{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3eef12d",
   "metadata": {},
   "source": [
    "# Pandas 2.2.2用\n",
    "\n",
    "## 0) 前提\n",
    "\n",
    "* 環境: **Python 3.10.15 / pandas 2.2.2**\n",
    "* **指定シグネチャ厳守**（関数名・引数名・返却列・順序）\n",
    "* I/O 禁止、不要な `print` や `sort_values` 禁止\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "* `同じ (actor_id, director_id) の組が 3 回以上 協働しているペアを抽出せよ。`\n",
    "* 入力 DF: `ActorDirector(actor_id: int, director_id: int, timestamp: int)`（行=協働の発生、`timestamp` は一意）\n",
    "* 出力: `actor_id, director_id`（重複なし・順不同）\n",
    "\n",
    "## 2) 実装（指定シグネチャ厳守）\n",
    "\n",
    "> 原則は **列最小化 → グループ処理（集計） → 条件抽出 → 最終投影**。最小メモリで確定できます。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def find_cooperative_pairs(actor_director: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['actor_id', 'director_id']\n",
    "    \"\"\"\n",
    "    # 1) 列最小化（必要列のみ）\n",
    "    df = actor_director[['actor_id', 'director_id']]\n",
    "\n",
    "    # 2) ペア単位で件数を集計\n",
    "    cnt = (\n",
    "        df.groupby(['actor_id', 'director_id'], as_index=False)\n",
    "          .size()  # → columns: ['actor_id','director_id','size']\n",
    "    )\n",
    "\n",
    "    # 3) しきい値（3回以上）で抽出\n",
    "    kept = cnt.loc[cnt['size'] >= 3, ['actor_id', 'director_id']]\n",
    "\n",
    "    # 4) 仕様列のみ返却（順不同・重複なし）\n",
    "    return kept\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 282 ms\n",
    "Beats 63.13%\n",
    "Memory 67.90 MB\n",
    "Beats 28.71%\n",
    "\n",
    "```\n",
    "\n",
    "### 代替（`transform` を使ったセミジョイン風：等価・やや重め）\n",
    "\n",
    "```python\n",
    "def find_cooperative_pairs_alt(actor_director: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = actor_director[['actor_id', 'director_id']]\n",
    "    coop_cnt = df.groupby(['actor_id', 'director_id'])['actor_id'].transform('size')\n",
    "    kept_pairs = df.loc[coop_cnt >= 3, ['actor_id', 'director_id']].drop_duplicates()\n",
    "    return kept_pairs\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 305 ms\n",
    "Beats 27.71%\n",
    "Memory 67.52 MB\n",
    "Beats 79.84%\n",
    "\n",
    "```\n",
    "\n",
    "## 3) アルゴリズム説明\n",
    "\n",
    "* 使用 API:\n",
    "\n",
    "  * `DataFrame.groupby(['actor_id','director_id']).size()`：ペアごとの出現回数を計算（ウィンドウ不要）\n",
    "  * `loc[...]`：閾値フィルタ\n",
    "  * `drop_duplicates()`：代替案での最終ユニーク化（標準案は不要）\n",
    "* **NULL / 重複 / 型**:\n",
    "\n",
    "  * 入力は整数想定で NULL なし（問題仕様）。NULL があり得る場合は前処理で `dropna(subset=[...])` を検討。\n",
    "  * `timestamp` は主キーだが本問では未使用（ID 基準の協働回数のみ必要）。\n",
    "  * 返却は **重複なし**・列順固定 `['actor_id','director_id']`。\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* `groupby.size()`：**O(N)** ～ **O(N log n_g)**（実装依存、平均は線形近似）\n",
    "* メモリ：ペア数に比例（`O(#unique(actor_id, director_id))`）\n",
    "\n",
    "## 5) 図解（Mermaid 超保守版）\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[入力 データフレーム]\n",
    "  B[列最小化 actor_id director_id]\n",
    "  C[グループ処理 size で回数集計]\n",
    "  D[条件抽出 回数が3以上]\n",
    "  E[出力 actor_id director_id]\n",
    "  A --> B\n",
    "  B --> C\n",
    "  C --> D\n",
    "  D --> E\n",
    "```\n",
    "\n",
    "**補足（パフォーマンスTips）**\n",
    "データが極端に大きい場合は、あらかじめ `actor_id, director_id` の順でソートされた入力（もしくは同キーでのパーティション投入）だと `groupby` のチャンク処理効率が上がることがあります（本回答は `sort_values` 禁止のため未使用）。また、複数問い合わせが繰り返されるワークロードでは、ペア→回数のサマリ DF をキャッシュする戦略が有効です。\n",
    "\n",
    "結論から：**`value_counts` 版**か**NumPy 版**が速く・メモリ効率も良いです。どちらも列最小化→集約→閾値抽出の原則は同じ。\n",
    "\n",
    "---\n",
    "\n",
    "## 改善案A（最小変更・Pandas最速パス）\n",
    "\n",
    "`groupby.size()`より内部パスが軽くなることが多いです（2.2系最適化の恩恵）。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def find_cooperative_pairs(actor_director: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: ['actor_id', 'director_id']\n",
    "    \"\"\"\n",
    "    df = actor_director[['actor_id', 'director_id']]\n",
    "\n",
    "    kept = (\n",
    "        df.value_counts(['actor_id', 'director_id'])     # Series: MultiIndex -> count\n",
    "          .loc[lambda s: s >= 3]                         # しきい値\n",
    "          .reset_index()[['actor_id', 'director_id']]    # 仕様列のみ\n",
    "    )\n",
    "    return kept\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 292 ms\n",
    "Beats 45.42%\n",
    "Memory 67.55 MB\n",
    "Beats 79.84%\n",
    "\n",
    "```\n",
    "\n",
    "**狙い**\n",
    "\n",
    "* `value_counts` は Cython 実装でハッシュ集約が速いケースが多い\n",
    "* 返すのがキーだけなので `reset_index()` → 列抜きで終了（`sort=False`は指定不要：順不同要件）\n",
    "\n",
    "---\n",
    "\n",
    "## 改善案B（NumPy直叩き・最大スループット）\n",
    "\n",
    "巨大データでさらに押し込みたいとき。`np.unique(axis=0)` は**整列副作用**がありますが、本件は「順不同」なので問題なし。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_cooperative_pairs_numpy(actor_director: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: ['actor_id', 'director_id']\n",
    "    \"\"\"\n",
    "    a = actor_director[['actor_id', 'director_id']].to_numpy(copy=False)\n",
    "    # uniques は辞書順にソートされる（順不同要件のためOK）\n",
    "    uniques, counts = np.unique(a, axis=0, return_counts=True)\n",
    "    res = uniques[counts >= 3]\n",
    "    return pd.DataFrame(res, columns=['actor_id', 'director_id'])\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 286 ms\n",
    "Beats 55.73%\n",
    "Memory 66.76 MB\n",
    "Beats 99.65%\n",
    "\n",
    "```\n",
    "\n",
    "**狙い**\n",
    "\n",
    "* 追加オブジェクトを最小化（`copy=False`）\n",
    "* `groupby`/`value_counts`よりも高速・低メモリになることがある（特に高重複×大件数）\n",
    "\n",
    "---\n",
    "\n",
    "## 微調整オプション（必要に応じて）\n",
    "\n",
    "* **dtypesの圧縮**：`int64` → `int32` でメモリを削減（IDが32bit範囲なら）\n",
    "\n",
    "  ```python\n",
    "  actor_director = actor_director.astype({'actor_id':'int32','director_id':'int32'}, copy=False)\n",
    "  ```\n",
    "* **カテゴリ化（高重複時）**：重複が極端に多ければ `category` 化 → `groupby.size()` が効くケースあり（ただしキャストコストがあるので要計測）\n",
    "\n",
    "  ```python\n",
    "  ad = actor_director.assign(\n",
    "      actor_id=actor_director['actor_id'].astype('category'),\n",
    "      director_id=actor_director['director_id'].astype('category')\n",
    "  )\n",
    "  # 以降は groupby.size() or value_counts で同様に\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## なぜ速いのか（短評）\n",
    "\n",
    "* `value_counts`：キー集合のハッシュ化→集計→Series出力の最短レーン。`groupby.size()`よりオーバーヘッドが少ない場面が多い。\n",
    "* NumPy：Pandasのインデクシング・アロケーションを回避し、配列ベースで一撃。`axis=0` の整列は発生するが、本問の要件と矛盾しない。\n",
    "\n",
    "---\n",
    "\n",
    "## まとめ（推奨順）\n",
    "\n",
    "1. **まずは `value_counts` 案**に差し替え（低リスク・高リターン）。\n",
    "2. さらに攻めたい or 超大規模なら **NumPy 案**。\n",
    "3. 併せて **`int32` 圧縮**でメモリを抑制。\n",
    "\n",
    "この順で置き換えると、提示の **282ms → 200ms前後（環境次第）**まで狙える余地があります。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
