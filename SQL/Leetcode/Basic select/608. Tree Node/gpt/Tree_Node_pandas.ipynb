{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 2.2.2用\n",
    "\n",
    "## 0) 前提\n",
    "\n",
    "* 環境: **Python 3.10.15 / pandas 2.2.2**\n",
    "* **指定シグネチャ厳守**（関数名・引数名・返却列・順序）\n",
    "* I/O 禁止、不要な `print` や `sort_values` 禁止\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "* `各ノードを Root / Inner / Leaf に分類して返す。`\n",
    "* 入力 DF: `Tree(id: int, p_id: int | NaN)`\n",
    "* 出力: `id, type`\n",
    "\n",
    "  * `p_id` が `NaN` → `\"Root\"`\n",
    "  * 親あり かつ 子なし → `\"Leaf\"`\n",
    "  * 親あり かつ 子あり → `\"Inner\"`\n",
    "\n",
    "## 2) 実装（指定シグネチャ厳守）\n",
    "\n",
    "> 列最小化 → 親ID集合（`p_id`）のユニーク化 → `isin` と `np.where` のベクトル化判定。\n",
    "> `groupby` や `merge` は不要で、**O(N)**・1パスで分類します。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def classify_tree_nodes(tree: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tree (pd.DataFrame): 列 'id', 'p_id' を持つデータフレーム\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['id', 'type']\n",
    "    \"\"\"\n",
    "    # 列最小化\n",
    "    t = tree[['id', 'p_id']].copy()\n",
    "\n",
    "    # 子を持つノード集合（= p_id に出現する id）\n",
    "    parent_ids = pd.Index(t['p_id'].dropna().unique())\n",
    "\n",
    "    # ベクトル化判定\n",
    "    is_root = t['p_id'].isna()\n",
    "    has_child = t['id'].isin(parent_ids)\n",
    "\n",
    "    node_type = np.where(\n",
    "        is_root, 'Root',\n",
    "        np.where(has_child, 'Inner', 'Leaf')\n",
    "    )\n",
    "\n",
    "    # 出力（列順固定）\n",
    "    out = pd.DataFrame({'id': t['id'].values, 'type': node_type})\n",
    "    return out\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 282 ms\n",
    "Beats 86.82%\n",
    "Memory 67.08 MB\n",
    "Beats 64.44%\n",
    "\n",
    "```\n",
    "\n",
    "## 3) アルゴリズム説明\n",
    "\n",
    "* 使用 API\n",
    "\n",
    "  * `Series.dropna().unique()`：`p_id` のユニーク親集合を抽出\n",
    "  * `Index.isin`：各 `id` が親集合に含まれるかを高速判定\n",
    "  * `np.where`：三分岐（Root / Inner / Leaf）をベクトル化で計算\n",
    "* **NULL / 重複 / 型**\n",
    "\n",
    "  * ルート判定は `p_id.isna()` を明示\n",
    "  * `p_id` に `NaN` があるため、親集合作成時は `dropna()` を必ず通す\n",
    "  * 型はそのまま扱い、`id` は入力のまま返却（順序指定が無いので並べ替えなし）\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* 親集合の作成：`dropna` + `unique` → **O(N)**\n",
    "* `isin` による包含判定：**O(N)**\n",
    "* 全体：**O(N)**、追加メモリは `parent_ids` と `node_type` 分\n",
    "\n",
    "## 5) 図解（Mermaid 超保守版）\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[入力 データフレーム Tree]\n",
    "  B[列最小化 id p_id のみ]\n",
    "  C[p_id から親ID集合を作成 unique]\n",
    "  D[id が親集合に含まれるかを判定]\n",
    "  E[p_id が NaN なら Root そうで親ありは Inner それ以外 Leaf]\n",
    "  F[出力 id type]\n",
    "  A --> B\n",
    "  B --> C\n",
    "  B --> D\n",
    "  C --> D\n",
    "  D --> E\n",
    "  E --> F\n",
    "```\n",
    "\n",
    "さらに数％〜2桁％の改善が狙える**配列直叩き（NumPy 主体）**版をご提案します。ポイントは「**DataFrame/Index を極力作らず**、`Series.values/to_numpy()` と `np.in1d`・ブール代入で一気に仕上げる」ことです。\n",
    "\n",
    "# Pandas 2.2.2用\n",
    "\n",
    "## 0) 前提\n",
    "\n",
    "* 環境: **Python 3.10.15 / pandas 2.2.2**\n",
    "* **指定シグネチャ厳守**\n",
    "* I/O 禁止、`print` / `sort_values` 不要\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "* `各ノードを Root / Inner / Leaf に分類して返す。`\n",
    "* 入力 DF: `Tree(id: int, p_id: int | NaN)`\n",
    "* 出力: `id, type`（順序任意）\n",
    "\n",
    "## 2) 実装（指定シグネチャ厳守）\n",
    "\n",
    "> **DataFrame/Index オブジェクト化を避ける**→ `Series.to_numpy()` と `np.in1d(assume_unique=True)` を活用。\n",
    "> `id` は一意という仕様を前提に `assume_unique=True` を使い、`np.where` ではなく**ブール代入**で 3 区分を埋めます。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def classify_tree_nodes(tree: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tree (pd.DataFrame): 列 'id', 'p_id' を持つデータフレーム\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['id', 'type']\n",
    "    \"\"\"\n",
    "    # 参照だけ取得（コピーを作らない）\n",
    "    id_s = tree['id']\n",
    "    p_s  = tree['p_id']\n",
    "\n",
    "    # 配列として取得（na_value の指定は不要。pandas は NaN で来る）\n",
    "    ids = id_s.to_numpy()\n",
    "    parents = p_s.to_numpy()\n",
    "\n",
    "    # 親IDのユニーク集合（NaN 除去）を「配列」で確保\n",
    "    mask_parent = ~pd.isna(parents)\n",
    "    parent_unique = pd.unique(parents[mask_parent])\n",
    "\n",
    "    # 子を持つか（id ∈ parent_unique）\n",
    "    # id は一意という仕様 → assume_unique=True が安全に使える\n",
    "    has_child = np.in1d(ids, parent_unique, assume_unique=True)\n",
    "\n",
    "    # ルートか\n",
    "    is_root = pd.isna(parents)\n",
    "\n",
    "    # 三分岐はブール代入で埋める（np.where ネストよりわずかに軽い）\n",
    "    out_type = np.empty(ids.shape[0], dtype=object)\n",
    "    out_type[is_root] = 'Root'\n",
    "    non_root = ~is_root\n",
    "    out_type[non_root & has_child] = 'Inner'\n",
    "    out_type[non_root & ~has_child] = 'Leaf'\n",
    "\n",
    "    # 出力（列順固定、並べ替え無し）\n",
    "    return pd.DataFrame({'id': ids, 'type': out_type})\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 263 ms\n",
    "Beats 99.37%\n",
    "Memory 66.91 MB\n",
    "Beats 73.85%\n",
    "\n",
    "```\n",
    "\n",
    "### マイクロ最適化の意図\n",
    "\n",
    "* **Index/Series を作らない**: `pd.Index(...)` や `Series.isin` は便利ですがオーバーヘッド増。\n",
    "  → `pd.unique` + `np.in1d` に寄せると軽くなりやすいです。\n",
    "* **`assume_unique=True`**: `id` は一意、`parent_unique` はすでにユニーク → `in1d` が高速化。\n",
    "* **三分岐は代入**: `np.where` ネストより、事前に `non_root` を作って3本のブール代入で埋める方が薄い計算量で済みます。\n",
    "* **コピー削減**: 中間 DataFrame を作らず、配列で完結。\n",
    "\n",
    "## 3) アルゴリズム説明\n",
    "\n",
    "* 使用 API\n",
    "\n",
    "  * `Series.to_numpy()`：配列化で軽量計算\n",
    "  * `pd.unique`：`p_id` のユニーク親集合（NaN 除去後）を抽出\n",
    "  * `np.in1d(..., assume_unique=True)`：`id` が親集合に含まれるかを高速判定\n",
    "* **NULL / 重複 / 型**\n",
    "\n",
    "  * ルート判定は `pd.isna(p_s)` を明示\n",
    "  * `id` は仕様上一意 → `assume_unique=True` を安全に使用\n",
    "  * 返却 dtype は `type=object`（審査系の比較に無難）。\n",
    "    もし許容されるなら `astype('category')` でメモリ削減可（下記参照）\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* 親集合作成：`O(N)`\n",
    "* 包含判定（`in1d`）：`O(N + U)`（U は `parent_unique` のサイズ）\n",
    "* 全体：**O(N)**、追加メモリは `parent_unique` と `out_type` 分のみ\n",
    "\n",
    "## 追加の微調整（必要に応じて）\n",
    "\n",
    "* **メモリ削減（返却時のみ）**\n",
    "  審査が dtype 非依存なら:\n",
    "\n",
    "  ```python\n",
    "  # 返却直前\n",
    "  # df = pd.DataFrame({'id': ids, 'type': out_type})\n",
    "  # df['type'] = pd.Categorical(df['type'], categories=['Root','Inner','Leaf'])\n",
    "  ```\n",
    "\n",
    "  これで `type` 列を category 化し、数十 % メモリを圧縮できます（Runtime 影響は小〜微増）。\n",
    "\n",
    "* **nullable 整数のまま扱いたい場合**\n",
    "  入力が `Int64`（nullable 整数）なら、そのまま配列化しても問題ありません。\n",
    "  内部的には `NaN` 判定のみ行い、`id` は値をそのまま返します。\n",
    "\n",
    "---\n",
    "\n",
    "**まとめ**\n",
    "現状の 282ms/67MB は十分優秀ですが、上記の**配列直叩き版**は多くの環境でさらに軽くなる傾向があります。\n",
    "特に `pd.Index`・`Series.isin` を外し、`pd.unique` + `np.in1d(assume_unique=True)` に寄せるのが効きどころです。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
