{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61602ed9",
   "metadata": {},
   "source": [
    "## 0) 前提\n",
    "\n",
    "* 環境: **Python 3.10.15 / pandas 2.2.2**\n",
    "* シグネチャ（LeetCode 想定）:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def sales_analysis(sales: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:\n",
    "    ...\n",
    "```\n",
    "\n",
    "* 制約:\n",
    "\n",
    "  * IO なし\n",
    "  * `print` / `sort_values` 不使用\n",
    "* 判定は ID 基準:\n",
    "\n",
    "  * `product.product_id`（商品マスタ）\n",
    "  * `sales.product_id`（売上側 FK → マスタ）\n",
    "\n",
    "---\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "### PROBLEM_STATEMENT\n",
    "\n",
    "`Sales` と `Product` の 2 つのテーブル（DataFrame）がある。\n",
    "\n",
    "* **Sales**\n",
    "\n",
    "  * 各行は、ある年における `product_id` の販売\n",
    "  * `price` は 1 単位あたりの単価\n",
    "* **Product**\n",
    "\n",
    "  * 各 `product_id` ごとの `product_name`\n",
    "\n",
    "**各 sale_id について**, 対応する `product_name`, `year`, `price` を出力せよ。\n",
    "結果の行順は任意。\n",
    "\n",
    "### 入力 DF（INPUT_DATAFRAMES）\n",
    "\n",
    "* `sales: pd.DataFrame`\n",
    "\n",
    "  * 列: `['sale_id', 'product_id', 'year', 'quantity', 'price']`\n",
    "* `product: pd.DataFrame`\n",
    "\n",
    "  * 列: `['product_id', 'product_name']`\n",
    "\n",
    "### 出力（OUTPUT_COLUMNS_AND_RULES）\n",
    "\n",
    "* 戻り値: `pd.DataFrame`\n",
    "* 列名・順序:\n",
    "\n",
    "```text\n",
    "['product_name', 'year', 'price']\n",
    "```\n",
    "\n",
    "* 各行は `Sales` の 1 レコードに対応\n",
    "\n",
    "---\n",
    "\n",
    "## 2) 実装（指定シグネチャ厳守）\n",
    "\n",
    "> この問題は **グループ処理不要** なので、\n",
    "> 「列最小化 → 軽量 `map` で名前付与 → 必要列だけ DataFrame 化」が最短です。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def sales_analysis(sales: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['product_name', 'year', 'price']\n",
    "    \"\"\"\n",
    "    # 1) Product 側を「product_id → product_name」のマッピングに圧縮\n",
    "    key_to_name = product.set_index('product_id')['product_name']\n",
    "\n",
    "    # 2) Sales の product_id をマップして product_name を付与し、\n",
    "    #    year と price はそのまま流用して新しい DataFrame を構成\n",
    "    out = pd.DataFrame({\n",
    "        'product_name': sales['product_id'].map(key_to_name),\n",
    "        'year': sales['year'],\n",
    "        'price': sales['price'],\n",
    "    })\n",
    "\n",
    "    return out\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 375 ms\n",
    "Beats 20.66%\n",
    "Memory 69.10 MB\n",
    "Beats 99.76%\n",
    "\n",
    "```\n",
    "\n",
    "* 列順は dict リテラルの順序どおり → `['product_name', 'year', 'price']`\n",
    "* `sort_values` / `print` 未使用\n",
    "* groupby / rank も不要なため使っていない\n",
    "\n",
    "---\n",
    "\n",
    "## 3) アルゴリズム説明\n",
    "\n",
    "使っている主な API は以下の通りです。\n",
    "\n",
    "1. **`set_index`**\n",
    "\n",
    "   * `product.set_index('product_id')['product_name']`\n",
    "   * `product_id` をインデックスにして、`product_name` だけ取り出した `Series` を作成\n",
    "   * これで「単一キー → 単一値」のマップを構築\n",
    "\n",
    "2. **`map`**\n",
    "\n",
    "   * `sales['product_id'].map(key_to_name)`\n",
    "   * 各 `product_id` に対して、対応する `product_name` を引く\n",
    "   * PK（`product_id` 一意）前提のため、`merge` より軽量な 1 対 1 置換として最適\n",
    "\n",
    "3. **DataFrame の再構成**\n",
    "\n",
    "   * `pd.DataFrame({...})` で必要列のみをまとめる\n",
    "   * 余計な列（`sale_id`, `quantity` 等）は出力しない\n",
    "\n",
    "### NULL / 重複 / 型まわり\n",
    "\n",
    "* **重複**\n",
    "\n",
    "  * `Product.product_id` は PK なので重複の心配なし\n",
    "  * よって `map` で「どの値を取るか」問題は発生しない\n",
    "* **NULL**\n",
    "\n",
    "  * 正常系では `Sales.product_id` は FK → `Product` 側に必ず存在する前提\n",
    "  * もし存在しない場合は `product_name` が `NaN` になるが、問題文の前提上考慮不要\n",
    "* **型**\n",
    "\n",
    "  * `product_id` は両 DataFrame で `int` 想定\n",
    "  * 型がズレるとマッピングできないので、実務なら `astype` で揃えるが、LeetCode では前提一致\n",
    "\n",
    "---\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* `product.set_index('product_id')['product_name']`\n",
    "\n",
    "  * インデックス構築: **O(M)**\n",
    "* `sales['product_id'].map(key_to_name)`\n",
    "\n",
    "  * 各行でハッシュルックアップ: **O(N)** 近似\n",
    "* DataFrame 再構成: **O(N)**\n",
    "\n",
    "ここで\n",
    "\n",
    "* `N = len(sales)`\n",
    "* `M = len(product)`\n",
    "\n",
    "よって全体は **O(N + M)**。\n",
    "`merge` でも実質同程度ですが、「1 対 1 マッピング」前提なら `map` の方がコードもコストも少しだけ軽い実装になります。\n",
    "\n",
    "---\n",
    "\n",
    "## 5) 図解（Mermaid 超保守版）\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[入力 sales DataFrame]\n",
    "  B[入力 product DataFrame]\n",
    "  C[product を product_id と product_name に圧縮してマップ作成]\n",
    "  D[sales の product_id に map で product_name を付与]\n",
    "  E[year と price をそのまま利用して列を構成]\n",
    "  F[出力 product_name year price の DataFrame]\n",
    "\n",
    "  A --> D\n",
    "  B --> C\n",
    "  C --> D\n",
    "  D --> E\n",
    "  E --> F\n",
    "```\n",
    "\n",
    "この問題は、「**Pandas での JOIN 相当処理は `merge` だけでなく `map` も強力**」というパターンを押さえておくと、後続の問題でもかなり使い回せます。\n",
    "\n",
    "結論から言うと：\n",
    "\n",
    "> **アルゴリズム的にはほぼ最適**で、375ms / Beats 20% は「悪くないが特別速くもない」くらい。\n",
    "> 大きく改善する余地は小さいですが、**実装スタイルを少し変えてワンチャン狙う余地**はあります。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 現状の評価\n",
    "\n",
    "実装（`map` 版）はこんなイメージでした：\n",
    "\n",
    "```python\n",
    "key_to_name = product.set_index('product_id')['product_name']\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    'product_name': sales['product_id'].map(key_to_name),\n",
    "    'year': sales['year'],\n",
    "    'price': sales['price'],\n",
    "})\n",
    "```\n",
    "\n",
    "* 計算量: **O(N + M)**（N = sales 行数, M = product 行数）\n",
    "* 余計な処理なし（groupby / sort / 重複処理などゼロ）\n",
    "* メモリ: Beats 99.76% → 実際かなり優秀\n",
    "\n",
    "Runtime のパーセンタイルが低いのは、\n",
    "\n",
    "* LeetCode の pandas ランタイムが結構ブレる\n",
    "* `merge` ベース実装に最適化が効いている可能性\n",
    "\n",
    "あたりが効いていそうです。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 試す価値がある改善案（`merge` ベース）\n",
    "\n",
    "pandas の内部実装的には、**`merge`（ハッシュ結合）に最適化が乗りやすい**ことが多いので、\n",
    "以下のような **列最小化 → merge → 列並べ替え** パターンは試す価値があります。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def sales_analysis(sales: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['product_name', 'year', 'price']\n",
    "    \"\"\"\n",
    "    # 1) 列最小化（不要な列を抱えない）\n",
    "    sales_small = sales[['product_id', 'year', 'price']]\n",
    "    product_small = product[['product_id', 'product_name']]\n",
    "\n",
    "    # 2) 左結合（Sales ベース）で product_name を付与\n",
    "    merged = sales_small.merge(\n",
    "        product_small,\n",
    "        on='product_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 3) 仕様どおりの列のみ・順序に整形\n",
    "    out = merged[['product_name', 'year', 'price']]\n",
    "\n",
    "    return out\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 341 ms\n",
    "Beats 62.84%\n",
    "Memory 70.59 MB\n",
    "Beats 9.35%\n",
    "\n",
    "```\n",
    "\n",
    "### この書き方の狙い\n",
    "\n",
    "* **列最小化**\n",
    "\n",
    "  * `sales_small`, `product_small` で「ほんとうに使う列だけ」に絞る\n",
    "  * 中間 DataFrame の列数が少ないほど、結合やコピーのコストが減る\n",
    "* **`merge` の内部最適化に乗る**\n",
    "\n",
    "  * C 実装のハッシュ結合がフル活用されるので、環境によっては `map` より速くなることがある\n",
    "* **DataFrame の再構成を 1 回にする**\n",
    "\n",
    "  * `merged[['product_name', 'year', 'price']]` で slice するだけなので、\n",
    "    dict からの新規 DataFrame 構築よりわずかに有利なパターンもあり得る\n",
    "\n",
    "---\n",
    "\n",
    "## 3. もう一つの軽量案（`join` + index）\n",
    "\n",
    "`set_index` を使うなら、`map` ではなく `join` に寄せるパターンもあります。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def sales_analysis(sales: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['product_name', 'year', 'price']\n",
    "    \"\"\"\n",
    "    sales_small = sales[['product_id', 'year', 'price']]\n",
    "    product_idx = product.set_index('product_id')[['product_name']]\n",
    "\n",
    "    merged = sales_small.join(product_idx, on='product_id')\n",
    "\n",
    "    out = merged[['product_name', 'year', 'price']]\n",
    "\n",
    "    return out\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 345 ms\n",
    "Beats 57.03%\n",
    "Memory 70.14 MB\n",
    "Beats 65.28%\n",
    "\n",
    "```\n",
    "\n",
    "* `join(..., on='product_id')` は「左側の index を使って右側 index と結合」する仕組み\n",
    "* これも **O(N + M)** で、`merge` とほぼ同等の計算量\n",
    "\n",
    "---\n",
    "\n",
    "## 4. どこまで追うかの目安\n",
    "\n",
    "* 375ms / Beats 20.66% は、\n",
    "  pandas 問題としては **「普通〜やや遅めだけど許容範囲」** くらいの位置\n",
    "* すでに **メモリはほぼ最上位** なので、\n",
    "\n",
    "  * これ以上メモリを削る意味は薄い\n",
    "  * もし `merge`/`join` に変えてランタイムが少し良くなればラッキー、程度の世界\n",
    "\n",
    "正直、**アルゴリズムはもう最適レベル**なので、\n",
    "ここから先は「スタイル変更で実行エンジンのクセに乗るかどうか」の話になります。\n",
    "\n",
    "---\n",
    "\n",
    "### まとめ\n",
    "\n",
    "* 今の `map` 実装でも十分 OK（アルゴリズム的には改善余地ほぼなし）\n",
    "* それでも Runtime を追いたいなら：\n",
    "\n",
    "  * 上記の **`merge` + 列最小化** 版\n",
    "  * または **`join` + index** 版\n",
    "    を一度投げてみる価値はあります\n",
    "* いずれも計算量は同じで、差は「実装スタイル」と「エンジン側の最適化次第」です\n",
    "\n",
    "「学習として試す」なら `merge` 版を一度投げて、Runtime の変化を見ておくと今後の問題にも効いてきます 💡\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
