{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4822e96e",
   "metadata": {},
   "source": [
    "# PostgreSQL 16.6+\n",
    "\n",
    "## 0) 前提\n",
    "\n",
    "* エンジン: **PostgreSQL 16.6+**\n",
    "* 並び順: 任意（`ORDER BY` なし）\n",
    "* `NOT IN` 回避（本問では不使用）\n",
    "* 判定は **ID 基準**、表示は仕様どおり `actor_id, director_id`\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "* `同一の (actor_id, director_id) が3回以上出現する協働ペアを抽出せよ。`\n",
    "* 入力: `ActorDirector(actor_id int, director_id int, \"timestamp\" int PRIMARY KEY)`\n",
    "* 出力: `actor_id, director_id`（重複なし・順不同）\n",
    "\n",
    "---\n",
    "\n",
    "## 2) 最適解（単一クエリ）\n",
    "\n",
    "> PostgreSQL でも素直に **ウィンドウ + 外側で重複排除** で書けます（要件充足）。ただし実務では後述の **`GROUP BY` 案が最速**になりがち。\n",
    "\n",
    "```sql\n",
    "WITH pre AS (\n",
    "  SELECT actor_id, director_id\n",
    "  FROM ActorDirector\n",
    "),\n",
    "win AS (\n",
    "  SELECT\n",
    "    actor_id,\n",
    "    director_id,\n",
    "    COUNT(*) OVER (PARTITION BY actor_id, director_id) AS coop_cnt\n",
    "  FROM pre\n",
    ")\n",
    "SELECT DISTINCT\n",
    "  actor_id,\n",
    "  director_id\n",
    "FROM win\n",
    "WHERE coop_cnt >= 3;\n",
    "\n",
    "Runtime\n",
    "314\n",
    "ms\n",
    "Beats\n",
    "44.19%\n",
    "\n",
    "```\n",
    "\n",
    "### 代替（推奨：集約一発）\n",
    "\n",
    "> PostgreSQL のプランナは集約に強いので、こちらが概ね速いです。\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  actor_id,\n",
    "  director_id\n",
    "FROM ActorDirector\n",
    "GROUP BY actor_id, director_id\n",
    "HAVING COUNT(*) >= 3;\n",
    "\n",
    "Runtime\n",
    "295\n",
    "ms\n",
    "Beats\n",
    "69.28%\n",
    "\n",
    "```\n",
    "\n",
    "> 結果は同じ。**読みやすく、余計な行膨張もない**ため、まずはこれで。\n",
    "\n",
    "---\n",
    "\n",
    "## 3) 要点解説\n",
    "\n",
    "* **最小十分条件**は「ペア単位の件数 ≥ 3」だけ。\n",
    "  ウィンドウを使う場合も `COUNT(*) OVER (PARTITION BY ...)` で総回数を付与してから閾値抽出。\n",
    "* **集合演算としては `GROUP BY ... HAVING COUNT(*) >= 3` が最短ルート**。\n",
    "  ウィンドウ版は内側で行を複製するため I/O が増えやすい。\n",
    "* **列名** `timestamp` は予約語ではないものの関数と紛らうので、DDL 上はダブルクォートが安全（上の例は既存前提）。\n",
    "\n",
    "---\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* ウィンドウ: **O(Σ n_g log n_g)**（パーティション内の並べ替え/バッファリング次第）\n",
    "* 集約（推奨クエリ）: **O(N)**〜**O(N log N)**（HashAggregate or GroupAggregate）\n",
    "\n",
    "---\n",
    "\n",
    "## 5) 図解（Mermaid 超保守版）\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[入力 テーブル]\n",
    "  B[ペアごとに件数を算出]\n",
    "  C[しきい値 3 以上を抽出]\n",
    "  D[出力 actor_id director_id]\n",
    "  A --> B\n",
    "  B --> C\n",
    "  C --> D\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 実運用メモ（速度チューニング）\n",
    "\n",
    "* **インデックス**\n",
    "  集約を「並び順で一発巻き上げ」できる余地を作ります。\n",
    "\n",
    "  ```sql\n",
    "  CREATE INDEX ON ActorDirector (actor_id, director_id);\n",
    "  ```\n",
    "\n",
    "  * これで `GroupAggregate`（インデックス順）か `HashAggregate` のいずれか良い方を選びやすくなります。\n",
    "* **統計**\n",
    "\n",
    "  ```sql\n",
    "  ANALYZE ActorDirector;\n",
    "  ```\n",
    "\n",
    "  古い統計だとフルスキャンを選びがち。\n",
    "* **ワークメモリ**\n",
    "  大きめのグループ数で `HashAggregate` が溢れる場合はセッション単位で調整：\n",
    "\n",
    "  ```sql\n",
    "  SET work_mem = '128MB';  -- ワークロードに合わせて\n",
    "  ```\n",
    "* **確認**\n",
    "  `EXPLAIN (ANALYZE, BUFFERS)` で `HashAggregate` か `GroupAggregate`、`Rows Removed by Filter`、`Shared Hit/Read` を確認。\n",
    "  さらに縮める必要があれば、取り込みパイプラインで**サマリテーブル**（actor_id, director_id ごとの coop_cnt）をバッチ更新するのが王道です。\n",
    "\n",
    "結論：**`GROUP BY ... HAVING COUNT(*) >= 3` が最短コース**です。ここから先は**物理設計と実行計画**で詰めます。実装はそのまま、周辺を最適化しましょう。\n",
    "\n",
    "---\n",
    "\n",
    "## 推奨チューニング手順（優先度順）\n",
    "\n",
    "### 1) 複合インデックス（最重要）\n",
    "\n",
    "ペアの集約を**インデックス順で一発**に寄せます。\n",
    "\n",
    "```sql\n",
    "-- 既存トラフィックがあるなら同時作成を推奨\n",
    "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_actor_director\n",
    "  ON ActorDirector (actor_id, director_id);\n",
    "```\n",
    "\n",
    "効果：\n",
    "\n",
    "* `GroupAggregate` が **Index Only/Index Scan** ベースになりやすい\n",
    "* 返す列がキーのみのため **カバリング**（VMが立てば実質 Index Only Scan）\n",
    "\n",
    "### 2) 統計・可視化（Index Only Scan を狙う）\n",
    "\n",
    "```sql\n",
    "ANALYZE ActorDirector;         -- 統計更新（必須）\n",
    "VACUUM (ANALYZE) ActorDirector; -- 可視マップ(VM)を立てて Index Only Scan 率UP\n",
    "```\n",
    "\n",
    "* 可視マップが育つと「テーブル読み」回数が下がります。\n",
    "\n",
    "### 3) 充分ならウィンドウ版は封印\n",
    "\n",
    "ウィンドウは行を膨らませるので I/O 増。最速の本命は下記。\n",
    "\n",
    "```sql\n",
    "SELECT actor_id, director_id\n",
    "FROM ActorDirector\n",
    "GROUP BY actor_id, director_id\n",
    "HAVING COUNT(*) >= 3;\n",
    "```\n",
    "\n",
    "### 4) HashAggregate のスピル対策（必要時のみ）\n",
    "\n",
    "`EXPLAIN (ANALYZE, BUFFERS)` で HashAggregate がディスクに溢れていたら一時的に：\n",
    "\n",
    "```sql\n",
    "SET work_mem = '128MB';  -- ワークロードに合わせ調整\n",
    "-- 比較用（悪化する場合もあるので計測前提）\n",
    "SET enable_hashagg = on;      -- 既定\n",
    "-- or\n",
    "SET enable_hashagg = off;     -- GroupAggregate に寄せる比較用\n",
    "```\n",
    "\n",
    "* **spilling**（Disk: ～MB）が消えるか、`GroupAggregate` で高速化するかを計測。\n",
    "\n",
    "### 5) 並列実行の活用（テーブルが大きい場合）\n",
    "\n",
    "```sql\n",
    "SET max_parallel_workers_per_gather = 2;  -- 環境許容量に応じて\n",
    "```\n",
    "\n",
    "* `Parallel Index/Seq Scan + Parallel Hash/Group Aggregate` を取りやすくなります。\n",
    "\n",
    "### 6) 物理配置の最適化（更新が少ないなら）\n",
    "\n",
    "```sql\n",
    "-- インデックス順に再配置（ダウンタイム許容時）\n",
    "CLUSTER ActorDirector USING idx_actor_director;\n",
    "-- オンラインなら pg_repack も選択肢\n",
    "```\n",
    "\n",
    "* `(actor_id, director_id)` で連続化 → キャッシュ効率改善。\n",
    "\n",
    "---\n",
    "\n",
    "## EXPLAIN チェックリスト（理想像）\n",
    "\n",
    "* `GroupAggregate` or `HashAggregate` がトップ\n",
    "* `key=idx_actor_director` を使っている（`Index Scan/Index Only Scan`）\n",
    "* `Extra`/出力に **Disk: 0**（スピルなし）\n",
    "* `Shared Read` が小さく、`Hit` が多い\n",
    "* `Rows Removed by Filter` が少ない（余計な読みが少ない）\n",
    "\n",
    "---\n",
    "\n",
    "## 規模がさらに大きい場合の構造策\n",
    "\n",
    "### サマリテーブル（マテビュー代替）\n",
    "\n",
    "高頻度の照会なら恒常的に最速です。\n",
    "\n",
    "```sql\n",
    "-- 初期構築\n",
    "CREATE TABLE CoopSummary AS\n",
    "SELECT actor_id, director_id, COUNT(*) AS coop_cnt\n",
    "FROM ActorDirector\n",
    "GROUP BY actor_id, director_id;\n",
    "\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ux_coop ON CoopSummary(actor_id, director_id);\n",
    "\n",
    "-- 照会は\n",
    "SELECT actor_id, director_id\n",
    "FROM CoopSummary\n",
    "WHERE coop_cnt >= 3;\n",
    "```\n",
    "\n",
    "更新はバッチで増分反映（新着分を集計→`INSERT ... ON CONFLICT ... DO UPDATE`）。\n",
    "\n",
    "---\n",
    "\n",
    "## 期待できる改善幅（目安）\n",
    "\n",
    "* **インデックス + 統計更新**だけで、350ms → **100ms台**は十分現実的（データ量・I/O次第）。\n",
    "* さらに **Index Only Scan** や **並列化**、**物理配置**が噛むと二桁msに入るケースも。\n",
    "\n",
    "---\n",
    "\n",
    "## まとめ（実行順）\n",
    "\n",
    "1. `CREATE INDEX CONCURRENTLY ON ActorDirector(actor_id, director_id);`\n",
    "2. `VACUUM (ANALYZE) ActorDirector;`\n",
    "3. 本命クエリは `GROUP BY ... HAVING COUNT(*) >= 3`\n",
    "4. まだ遅ければ `work_mem` / `enable_hashagg` を計測調整\n",
    "5. それでも重い常用クエリなら **サマリテーブル**化\n",
    "\n",
    "この順で叩けば、現状（295ms/314ms）から**まだ削れます**。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
