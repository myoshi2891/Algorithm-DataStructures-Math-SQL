{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63101f51",
   "metadata": {},
   "source": [
    "# Pandas 2.2.2用\n",
    "\n",
    "## 0) 前提\n",
    "\n",
    "* 環境: **Python 3.10.15 / pandas 2.2.2**\n",
    "* **指定シグネチャ厳守**（関数名・引数名・返却列・順序）\n",
    "* I/O 禁止、不要な `print` や `sort_values` 禁止\n",
    "\n",
    "## 1) 問題\n",
    "\n",
    "* `MyNumbers` から **ちょうど1回だけ出現する数（single number）** のうち **最大の数**を 1 行で返す。存在しなければ `NULL` を返す。\n",
    "* 入力 DF: `MyNumbers(num: int)`\n",
    "* 出力: `num`（1行1列、single number の最大。なければ `NULL`）\n",
    "\n",
    "## 2) 実装（指定シグネチャ厳守）\n",
    "\n",
    "> 列最小化 → 出現回数（`value_counts`）→ 出現1回の要素だけ残す → `max`。`sort_values` は使わず、`LIMIT` 相当の早期終了も不要。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def largest_single_number(my_numbers: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        my_numbers (pd.DataFrame): 列 'num' を持つ DataFrame（重複可）\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['num']（1行1列）。single number がなければ NULL（pd.NA）を返す。\n",
    "    \"\"\"\n",
    "    # 対象列のみ（列最小化）\n",
    "    s = my_numbers['num']\n",
    "\n",
    "    # 各値の出現回数（NaNを数える必要がなければ dropna=True でもよいが、max は NaN を無視するため既定のままでOK）\n",
    "    vc = s.value_counts(dropna=False)\n",
    "\n",
    "    # 出現1回である行だけを抽出（セミジョイン相当）\n",
    "    mask_single = s.map(vc).eq(1)\n",
    "    candidates = s[mask_single]\n",
    "\n",
    "    # 最大値を1行で返す。候補が空なら NULL（pd.NA）\n",
    "    if candidates.empty:\n",
    "        out = pd.DataFrame({'num': [pd.NA]})\n",
    "    else:\n",
    "        out = pd.DataFrame({'num': [candidates.max()]})\n",
    "\n",
    "    return out\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 298 ms\n",
    "Beats 33.33%\n",
    "Memory 67.06 MB\n",
    "Beats 47.82%\n",
    "\n",
    "```\n",
    "\n",
    "## 3) アルゴリズム説明\n",
    "\n",
    "* 使用 API\n",
    "\n",
    "  * `Series.value_counts(dropna=False)`: 値ごとの出現回数を計算（ハッシュベース）\n",
    "  * `Series.map(vc)`: 各行に出現回数を付与（軽量結合）\n",
    "  * ブールフィルタで `== 1` を抽出\n",
    "  * `Series.max()`: single 値の中の最大値を取得（`NaN` は既定で無視）\n",
    "* **NULL / 重複 / 型**\n",
    "\n",
    "  * `NaN` が1回だけでも `Series.max()` は無視するため、非NULLの single があればそちらが選ばれる（SQL の `MAX` と同等の直感）。\n",
    "  * 全ての single が存在しない場合（= 候補空）は `pd.NA` を返す。\n",
    "  * 返却列は1列のみ `num`。`pd.NA` を含み得るため dtype は `Int64` 互換か object になるが、仕様上は列名と値が重要。\n",
    "\n",
    "## 4) 計算量（概算）\n",
    "\n",
    "* `value_counts`（ハッシュ集計）: **O(N)**\n",
    "* `map` による付番＋フィルタ: **O(N)**\n",
    "* `max`: **O(K)**（K は single の件数）\n",
    "  合計 **O(N)** 近似、追加メモリは一時ハッシュ（一意値数に比例）。\n",
    "\n",
    "## 5) 図解（Mermaid 超保守版）\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[入力 データフレーム]\n",
    "  B[前処理 列最小化]\n",
    "  C[出現回数を計算 value_counts]\n",
    "  D[map で行に回数を付与]\n",
    "  E[回数が1回の行だけ抽出]\n",
    "  F[max で最大の数を取得]\n",
    "  G[出力 列 num だけ]\n",
    "  A --> B\n",
    "  B --> C\n",
    "  C --> D\n",
    "  D --> E\n",
    "  E --> F\n",
    "  F --> G\n",
    "```\n",
    "\n",
    "ポイントは **「全行サイズの中間 Series を作らない」** ことと、**余計なソートを避ける**ことです。\n",
    "\n",
    "---\n",
    "\n",
    "## 改善ポイント（効果順）\n",
    "\n",
    "1. **`value_counts(sort=False)` を使ってソートを抑止**\n",
    "   既定では並べ替えが走ることがありコスト増。`sort=False` で純粋なハッシュ集計にします。\n",
    "\n",
    "2. **`map`／全行マスクをやめて「ユニーク値側だけ」で最大値を決める**\n",
    "   `value_counts` の結果（= ユニーク値ごとの回数）から **出現1回のキー**だけ抽出し、その **キー集合の最大**を取れば、元 Series 全体に戻してブールマスクを作る必要がありません。\n",
    "   → メモリも CPU も削減。\n",
    "\n",
    "3. （オプション）**超大規模なら NumPy 直利用**\n",
    "   `np.unique(..., return_counts=True)` で同様のことができます。pandas 生成物を最小化できるので、極端に大きいデータで効くことがあります。\n",
    "\n",
    "---\n",
    "\n",
    "## 改良版（純 pandas・シグネチャ厳守）\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def largest_single_number(my_numbers: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        my_numbers (pd.DataFrame): 列 'num' を持つ DataFrame（重複可）\n",
    "    Returns:\n",
    "        pd.DataFrame: 列名と順序は ['num']（1行1列）。single number がなければ NULL（pd.NA）を返す。\n",
    "    \"\"\"\n",
    "    s = my_numbers['num']\n",
    "\n",
    "    # ユニーク値ごとの出現回数。sort=False で余計な並び替えを抑止\n",
    "    vc = s.value_counts(dropna=False, sort=False)\n",
    "\n",
    "    # 出現1回の値だけ（Index）\n",
    "    singles = vc.index[vc.eq(1)]\n",
    "\n",
    "    if len(singles) == 0:\n",
    "        return pd.DataFrame({'num': [pd.NA]})\n",
    "\n",
    "    # 最大値（NaN/NA は無視）。すべてが NaN のときは NaN が返る → pd.NA に正規化\n",
    "    max_single = pd.Series(singles).max(skipna=True)\n",
    "    if pd.isna(max_single):\n",
    "        return pd.DataFrame({'num': [pd.NA]})\n",
    "\n",
    "    return pd.DataFrame({'num': [max_single]})\n",
    "```\n",
    "\n",
    "**変更点の狙い**\n",
    "\n",
    "* `map(vc)` と `mask_single`（長さ N の中間 Series）を **作成しない**ため、**メモリ削減**と **CPU 削減**。\n",
    "* `sort=False` で **集計のみ**に徹して高速化。\n",
    "* `max(skipna=True)` で **NULL 安全**（SQL の `MAX` 同等の直感）。\n",
    "\n",
    "---\n",
    "\n",
    "## さらに攻める版（NumPy 直利用・大規模向け）\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def largest_single_number(my_numbers: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = my_numbers['num']\n",
    "    vals = s.to_numpy(copy=False)\n",
    "\n",
    "    # unique と counts を同時取得（unique は dtype 依存でソートされますが影響なし）\n",
    "    uniq, cnts = np.unique(vals, return_counts=True)\n",
    "\n",
    "    # 出現1回の候補のみ\n",
    "    cand = uniq[cnts == 1]\n",
    "\n",
    "    if cand.size == 0:\n",
    "        return pd.DataFrame({'num': [pd.NA]})\n",
    "\n",
    "    # NaN を弾いて最大を取る（数値前提）\n",
    "    # 数値でない（object）可能性もあるので、pandas 経由で安全に最大を取る\n",
    "    max_single = pd.Series(cand).max(skipna=True)\n",
    "    if pd.isna(max_single):\n",
    "        return pd.DataFrame({'num': [pd.NA]})\n",
    "\n",
    "    return pd.DataFrame({'num': [max_single]})\n",
    "\n",
    "Analyze Complexity\n",
    "Runtime 242 ms\n",
    "Beats 98.12%\n",
    "Memory 66.85 MB\n",
    "Beats 62.31%\n",
    "\n",
    "```\n",
    "\n",
    "> 備考: `np.unique` は戻り値をソートしますが、**最大値を取るだけ**なので問題になりません（`sort_values` は未使用）。\n",
    "\n",
    "---\n",
    "\n",
    "## なぜ速く・軽くなるか\n",
    "\n",
    "* 以前の案は `map(vc)`→**長さ N の中間配列**を作っていました。\n",
    "  改良案は **ユニーク値個数（≪N のことが多い）だけ**を扱い、`max` もそこから計算します。\n",
    "* `value_counts(sort=False)` で **集計のみ**に限定し、不要な並び替えコストを排除。\n",
    "\n",
    "---\n",
    "\n",
    "## 概算計算量とメモリ\n",
    "\n",
    "* 集計: **O(N)**（ハッシュ）\n",
    "* 以降は **O(U)**（U=ユニーク値数）\n",
    "* 追加メモリ: ハッシュテーブル（U に比例）＋小さな中間（Series(singles)）\n",
    "\n",
    "---\n",
    "\n",
    "## 仕上げの小ネタ\n",
    "\n",
    "* `my_numbers['num']` の **dtype を整数系（nullable Int64）や適切な数値型に揃える**と、`value_counts` の内部ハッシュが効きやすいケースがあります。\n",
    "* 事前に `my_numbers = my_numbers[['num']]` と **列最小化**してから渡す（既に満たしていれば不要）。\n",
    "\n",
    "---\n",
    "\n",
    "これで **メモリ 1 枚分の中間 Series を削り**つつ、**余計な並べ替えをカット**できるので、`Runtime`/`Memory` ともに改善が見込めます。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
