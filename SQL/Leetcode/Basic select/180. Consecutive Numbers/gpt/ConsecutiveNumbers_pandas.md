# åŒã˜ `num` ãŒ **å°‘ãªãã¨ã‚‚ 3 å›é€£ç¶š** ã—ã¦å‡ºç¾ã™ã‚‹æ•°å€¤ã€ã‚’æ±‚ã‚ã‚‹å®Ÿè£…

---

## âœ… å®Ÿè£…ï¼ˆé–¢æ•° 1 æœ¬ã§åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼‰

```python
import pandas as pd

def consecutive_nums(logs: pd.DataFrame, method: str = "rle") -> pd.DataFrame:
    """
    Find numbers that appear at least three times consecutively (by id order).

    Parameters
    ----------
    logs : pd.DataFrame
        Columns: 'id' (int-like, unique), 'num' (str/int-like)
    method : {"rle", "rolling"}
        - "rle": Run-Length Encoding via change points (æ¨å¥¨: é•·ã„é€£ç¶šã«å¼·ã„)
        - "rolling": shiftã‚’ä½¿ã£ãŸç›´æ„Ÿçš„åˆ¤å®šï¼ˆçŸ­ã„ã‚³ãƒ¼ãƒ‰ï¼‰

    Returns
    -------
    pd.DataFrame
        Single column 'ConsecutiveNums' in any order (unique).
    """
    # 1) å…¥åŠ›ã®æœ€å°å‰å‡¦ç†
    df = logs.loc[:, ["id", "num"]].copy()
    df = df.sort_values("id", kind="mergesort")  # å®‰å®šã‚½ãƒ¼ãƒˆï¼ˆåŒidã¯ç„¡ã„æƒ³å®šã ãŒå®‰å…¨å´ï¼‰

    if method == "rolling":
        # 2A) rollingæ³•ï¼šç›´è¿‘2ã¤ã¨åŒã˜ãªã‚‰3é€£ç¶š
        m = df["num"].eq(df["num"].shift(1)) & df["num"].eq(df["num"].shift(2))
        out = df.loc[m, "num"].drop_duplicates()

    else:
        # 2B) RLEæ³•ï¼ˆæ¨å¥¨ï¼‰ï¼šå¤‰åŒ–ç‚¹ã§ run_id ã‚’æŒ¯ã£ã¦åŒºé–“é•·ã‚’é›†è¨ˆ
        df["run_id"] = (df["num"] != df["num"].shift(1)).cumsum()
        run = (
            df.groupby(["num", "run_id"], sort=False)
              .size()
              .reset_index(name="run_len")
        )
        out = run.loc[run["run_len"] >= 3, "num"].drop_duplicates()

    return pd.DataFrame({"ConsecutiveNums": out})
```

### ä½¿ã„æ–¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ï¼‰

```python
logs = pd.DataFrame(
    {"id":[1,2,3,4,5,6,7], "num":[1,1,1,2,1,2,2]}
)
print(consecutive_nums(logs, method="rle"))
#   ConsecutiveNums
# 0               1

print(consecutive_nums(logs, method="rolling"))
#   ConsecutiveNums
# 0               1
```

---

## ğŸ§  ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£èª¬

### æ–¹æ³• Aï¼šRLEï¼ˆRun-Length Encodingï¼‰æ³•ã€æ¨å¥¨ã€‘

- `num` ãŒå¤‰ã‚ã£ãŸå ´æ‰€ã§ **å¤‰åŒ–ãƒ•ãƒ©ã‚°** ã‚’ç«‹ã¦ã€ç´¯ç©å’Œã§ **run_id** ã‚’æŒ¯ã‚‹
  ï¼ˆåŒã˜ `num` ãŒç¶šãåŒºé–“ã¯åŒã˜ run_id ã«ãªã‚‹ï¼‰
- `groupby(["num","run_id"])` ã§ **åŒºé–“é•·ï¼ˆrun_lenï¼‰** ã‚’é›†è¨ˆ
- `run_len >= 3` ã® `num` ã‚’é‡è¤‡æ’é™¤ã—ã¦è¿”ã™

**é•·æ‰€**ï¼šè¶…é•·ã„é€£ç¶šï¼ˆä¾‹ï¼š100 é€£ç¶šï¼‰ãŒã‚ã£ã¦ã‚‚ã€**åŒºé–“å˜ä½**ã§ 1 å›ã®é›†è¨ˆã«ç•³ã‚ã‚‹ãŸã‚å®‰å®šãƒ»é«˜é€Ÿã€‚

### æ–¹æ³• Bï¼šrollingï¼ˆshiftï¼‰æ³•

- `num == shift(1)` ã‹ã¤ `num == shift(2)` ã‚’æº€ãŸã™è¡ŒãŒã‚ã‚Œã°ã€ãã® `num` ã¯ 3 é€£ç¶š
- ãƒ’ãƒƒãƒˆã—ãŸè¡Œã‹ã‚‰ `num` ã‚’é‡è¤‡æ’é™¤

**é•·æ‰€**ï¼šã‚³ãƒ¼ãƒ‰ãŒçŸ­ãç›´æ„Ÿçš„ã€‚
**çŸ­æ‰€**ï¼šé•·ã„é€£ç¶šãŒå¤§é‡ã«ã‚ã‚‹ã¨ã€ãƒ’ãƒƒãƒˆè¡ŒãŒå¢—ãˆã¦å¾Œæ®µã®é‡è¤‡æ’é™¤ã‚³ã‚¹ãƒˆãŒã‚„ã‚„å¢—ãˆã‚‹ã€‚

---

## â±ï¸ è¨ˆç®—é‡ï¼ˆã©ã¡ã‚‰ã‚‚ç·šå½¢ï¼‰

- ã‚½ãƒ¼ãƒˆï¼š`O(n log n)`ï¼ˆ`id` ãŒæ—¢ã«æ˜‡é †ãªã‚‰çœç•¥å¯ â†’ å®Ÿè³ª `O(n)`ï¼‰
- RLE æ³•ï¼šã‚·ãƒ•ãƒˆãƒ»ç´¯ç©å’Œãƒ»groupby/size ã®åˆè¨ˆã§ **`O(n)`**
- rolling æ³•ï¼šã‚·ãƒ•ãƒˆ 2 å›ï¼‹ãƒ–ãƒ¼ãƒ«æ¼”ç®—ï¼‹é‡è¤‡æ’é™¤ã§ **`O(n)`**

---

## âœ… å›³è§£ï¼ˆGitHub Mermaid ã§å®‰å…¨ã«æç”»ã§ãã‚‹è¡¨è¨˜ï¼‰

### å›³ 1ï¼šRLE æ³•ã®æµã‚Œ

```mermaid
flowchart LR
  A["Sort by id"] --> B["Compute change flag: num != shift(num)"]
  B --> C["run_id = cumulative sum of change flag"]
  C --> D["Group by (num, run_id) and size"]
  D --> E{"run_len >= 3"}
  E -- Yes --> F["Collect num"]
  E -- No --> G["Skip"]
  F --> H["Drop duplicates"]
  H --> I["Return DataFrame: ConsecutiveNums"]
```

### å›³ 2ï¼šrolling æ³•ã®æµã‚Œ

```mermaid
flowchart LR
  A["Sort by id"] --> B["eq1 = num == shift(1)"]
  B --> C["eq2 = num == shift(2)"]
  C --> D["mask = eq1 and eq2"]
  D --> E["Filter rows where mask is True"]
  E --> F["Unique num"]
  F --> G["Return DataFrame: ConsecutiveNums"]
```

> æ³¨: æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã‚„ `<br/>` ã¯ä½¿ã‚ãšã€ãƒ©ãƒ™ãƒ«ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªè‹±èªæ–‡ã«ã™ã‚‹ã¨å®‰å®šã—ã¦æç”»ã§ãã¾ã™ã€‚

---

## ğŸ”§ å®Ÿå‹™ Tips

- **é€£ç¶šã®å®šç¾©**ãŒ `id` ã§ã¯ãªãã€Œæ™‚åˆ»åˆ—ã€ç­‰ã®å ´åˆã¯ã€`sort_values("timestamp")` ã«å·®ã—æ›¿ãˆã‚‹ã ã‘ã§ OKã€‚
- `num` ã®å‹ã¯æ–‡å­—åˆ—ã§ã‚‚æ•°å€¤ã§ã‚‚å‹•ãã¾ã™ï¼ˆãã®ã¾ã¾è¿”ã—ã¾ã™ï¼‰ã€‚æ•°å€¤ã«çµ±ä¸€ã—ãŸã„ãªã‚‰ `pd.to_numeric(df["num"], errors="coerce")` ã‚’æ¤œè¨ã€‚
- ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã« `id` æ˜‡é †ãªã‚‰ã€ä¸¦ã¹æ›¿ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã•ã‚‰ã«é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚

äº†è§£ã§ã™ã€‚æŒ‡å®šã®ã‚·ã‚°ãƒãƒãƒ£ã«æ²¿ã£ã¦ã€**RLEï¼ˆé€£ç¶šåŒºé–“ã®é•·ã•ã‚’æ•°ãˆã‚‹ï¼‰æ–¹å¼**ã§å®Ÿè£…ã—ã¾ã™ã€‚`id` æ˜‡é †ã‚’â€œé€£ç¶šâ€ã®åŸºæº–ã«ã—ã€3 å›ä»¥ä¸Šé€£ç¶šã—ãŸ `num` ã‚’ä¸€æ„ã«è¿”ã—ã¾ã™ã€‚

```python
import pandas as pd

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers that appear at least three times consecutively by id order.

    Parameters
    ----------
    logs : pd.DataFrame
        Must contain columns:
          - 'id'  : integer-like primary key
          - 'num' : value to check consecutive appearances (str/int)

    Returns
    -------
    pd.DataFrame
        Single column 'ConsecutiveNums' (unique values, any order).
    """
    # å¿…è¦åˆ—ã ã‘ã‚³ãƒ”ãƒ¼ã—ã€idæ˜‡é †ã§å®‰å®šã‚½ãƒ¼ãƒˆï¼ˆå¿µã®ãŸã‚ mergesort ã‚’æ˜ç¤ºï¼‰
    df = logs.loc[:, ["id", "num"]].copy()
    if df.empty:
        return pd.DataFrame({"ConsecutiveNums": pd.Series(dtype=df["num"].dtype if "num" in df else object)})

    df.sort_values("id", kind="mergesort", inplace=True)

    # ç›´å‰è¡Œã¨ num ãŒç•°ãªã‚‹ç®‡æ‰€ã‚’ã€Œå¤‰åŒ–ç‚¹ã€ã¨ã—ã¦æ¤œå‡ºã—ã€ç´¯ç©å’Œã§ run_id ã‚’ä»˜ä¸
    # åŒã˜ num ãŒç¶šãåŒºé–“ã¯åŒã˜ run_id ã«ãªã‚‹
    df["run_id"] = (df["num"].ne(df["num"].shift(1))).cumsum()

    # (num, run_id) ã”ã¨ã®åŒºé–“é•·ã‚’é›†è¨ˆã—ã€3ä»¥ä¸Šã®ã¿æŠ½å‡º â†’ num ã‚’ä¸€æ„åŒ–
    run = (
        df.groupby(["num", "run_id"], sort=False)
          .size()
          .reset_index(name="run_len")
    )
    out = run.loc[run["run_len"] >= 3, "num"].drop_duplicates()

    return pd.DataFrame({"ConsecutiveNums": out})
```

### ä½¿ã„æ–¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰

```python
logs = pd.DataFrame(
    {"id":[1,2,3,4,5,6,7], "num":[1,1,1,2,1,2,2]}
)
consecutive_numbers(logs)
#   ConsecutiveNums
# 0               1
```

---

## å›³è§£ï¼šå‡¦ç†ã®æµã‚Œï¼ˆMermaid å®‰å…¨è¡¨è¨˜ï¼‰

## å›³ 1ï¼šRLE æ–¹å¼ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
flowchart LR
  A["Sort by id"] --> B["Change flag = num != shift(num)"]
  B --> C["run_id = cumsum(change flag)"]
  C --> D["Group by (num, run_id) and size"]
  D --> E{"run_len >= 3"}
  E -- Yes --> F["Collect num"]
  E -- No  --> G["Skip"]
  F --> H["Drop duplicates"]
  H --> I["Return DataFrame: ConsecutiveNums"]
```

## å›³ 2ï¼šrun_id ã®ä»˜ãæ–¹ï¼ˆã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰

```mermaid
flowchart TB
  subgraph Input["id, num (ordered by id)"]
    X1["1, 1"] --> X2["2, 1"] --> X3["3, 1"] --> X4["4, 2"] --> X5["5, 1"] --> X6["6, 2"] --> X7["7, 2"]
  end
  subgraph RunID["run_id after cumsum(num != shift)"]
    R1["1"] --> R2["1"] --> R3["1"] --> R4["2"] --> R5["3"] --> R6["4"] --> R7["4"]
  end
  Input --> RunID
```

---

## è£œè¶³

- `id` ãŒã™ã§ã«æ˜‡é †ãªã‚‰ `sort_values` ã¯çœç•¥å¯ï¼ˆã•ã‚‰ã«é«˜é€Ÿï¼‰ã€‚
- `num` ãŒæ–‡å­—åˆ—ã§ã‚‚æ•°å€¤ã§ã‚‚å‹•ä½œã—ã¾ã™ï¼ˆè¿”å´ã‚‚åŒã˜å‹ï¼‰ã€‚
- â€œk å›ä»¥ä¸Šé€£ç¶šâ€ã«ä¸€èˆ¬åŒ–ã™ã‚‹å ´åˆã¯ã€`run_len >= 3` ã‚’ `>= k` ã«å¤‰ãˆã‚‹ã ã‘ã§ OKã€‚

åŸå› ã®å¯èƒ½æ€§ãŒé«˜ã„ã®ã¯æ¬¡ã® 2 ç‚¹ã§ã™ã€‚ã©ã¡ã‚‰ã‚‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¡ç‚¹ã§ã‚ˆãè½ã¡ã‚‹â€œåœ°é›·â€ã§ã™ã€‚

1. **`num` ã« `NaN`ï¼ˆæ¬ æï¼‰ãŒæ··ã–ã‚‹ã‚±ãƒ¼ã‚¹ã®æœªå¯¾å¿œ**
   ã€€ä»Šã®å®Ÿè£…ã ã¨ `NaN != NaN` ãŒå¸¸ã« `True` ã«ãªã‚‹ãŸã‚ã€
   `NaN` ã®é€£ç¶šãŒ **èª¤ã£ã¦ 1 ã¤ã®â€œæ•°å€¤â€ã¨ã—ã¦ 3 é€£ç¶šæ‰±ã„**ã•ã‚Œã€`ConsecutiveNums` ã« `NaN` ãŒç´›ã‚Œè¾¼ã¿ã¾ã™ï¼ˆæƒ³å®šå¤–ï¼‰ã€‚
2. **å‡ºåŠ›ã®æ±ºå®šæ€§ï¼ˆä¸¦ã³ãƒ»dtypeï¼‰ã®ä¸ä¸€è‡´**
   ã€€å•é¡Œæ–‡ã¯ã€Œé †ä¸åŒã§ OKã€ã§ã‚‚ã€æ¡ç‚¹å´ãŒå†…éƒ¨ã§æ¯”è¼ƒã™ã‚‹ã¨ãã« **ä¸¦ã³ã‚„ dtype ã®é•ã„**ã§å¼¾ã‹ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼ˆç‰¹ã«ç©ºçµæœã‚„å˜ä¸€çµæœï¼‰ã€‚

ä¸‹ã®ä¿®æ­£ç‰ˆã¯ â‘ `NaN` ã‚’**éå¯¾è±¡**ã¨ã—ã¦å®Œå…¨ã«é™¤å¤–ã—ã€â‘¡**æ±ºå®šçš„ãªä¸¦ã³**ï¼ˆå€¤ã§æ˜‡é †ï¼‰ã§è¿”ã—ã€â‘¢ ç©ºçµæœã§ã‚‚æ­£ã—ã„ã‚«ãƒ©ãƒ åãƒ»dtype ã§è¿”ã™ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

---

## ä¿®æ­£ç‰ˆï¼ˆRLE æ³•ãƒ»å®‰å…¨ç‰ˆï¼‰

```python
import pandas as pd

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers that appear at least three times consecutively by id order.

    Parameters
    ----------
    logs : pd.DataFrame
        Columns:
          - 'id'  : integer-like primary key
          - 'num' : value to check (str/int-like). NaN is ignored.

    Returns
    -------
    pd.DataFrame
        Single column 'ConsecutiveNums' (unique values, ascending, stable dtype).
    """
    # ç©ºã‚„å¿…è¦åˆ—æ¬ å¦‚ã®ã‚¬ãƒ¼ãƒ‰
    if logs is None or logs.empty or not {"id", "num"} <= set(logs.columns):
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="object")})

    # ä¸¦ã³ã®åŸºæº–ã¯ id æ˜‡é †
    df = logs.loc[:, ["id", "num"]].sort_values("id", kind="mergesort").copy()

    # NaN ã¯é€£ç¶šåˆ¤å®šã®å¯¾è±¡å¤–ï¼ˆå®Œå…¨é™¤å¤–ï¼‰
    df_valid = df[df["num"].notna()].copy()
    if df_valid.empty:
        # ç©ºã§ã‚‚å¿…ãšåˆ—åã¯ 'ConsecutiveNums'
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype=df["num"].dtype)})

    # å¤‰åŒ–ç‚¹ â†’ ç´¯ç©å’Œã§ run_idï¼ˆåŒã˜ num ãŒç¶šãåŒºé–“ã¯åŒä¸€ run_idï¼‰
    df_valid["run_id"] = (df_valid["num"].ne(df_valid["num"].shift(1))).cumsum()

    # åŒºé–“é•· >= 3 ã® num ã‚’ä¸€æ„ã«æŠ½å‡º
    run_len = (
        df_valid.groupby(["num", "run_id"], sort=False)
                .size()
                .reset_index(name="run_len")
    )
    winners = run_len.loc[run_len["run_len"] >= 3, "num"].drop_duplicates()

    # æ¡ç‚¹å®‰å®šæ€§ã®ãŸã‚å€¤ã§æ˜‡é †ã«æ•´åˆ—ï¼ˆæ•°å€¤ã¨æ–‡å­—ãŒæ··åœ¨ã—å¾—ã‚‹ãŸã‚ astype(str) ã§ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ã‚’ä½œã‚‹ï¼‰
    if not winners.empty:
        winners = winners.iloc[winners.astype(str).sort_values().index]

    return pd.DataFrame({"ConsecutiveNums": winners})
```

### å¤‰æ›´ç‚¹ã®è¦æ—¨

- **NaN å®Œå…¨é™¤å¤–**ï¼š`df_valid = df[df["num"].notna()]`
  â†’ `NaN` ãŒé€£ç¶šã—ã¦ã‚‚æ‹¾ã‚ãªã„ï¼è¿”ã•ãªã„ã€‚
- **æ±ºå®šçš„ãªæˆ»ã‚Šé †**ï¼š`astype(str)` ã®ã‚­ãƒ¼ã§æ˜‡é †ã‚½ãƒ¼ãƒˆ
  â†’ æ•°å€¤ã¨æ–‡å­—åˆ—ãŒæ··åœ¨ã—ã¦ã‚‚å®‰å®šã—ã¦æ¯”è¼ƒã§ãã€æ¡ç‚¹ãƒ–ãƒ¬ã‚’é˜²æ­¢ã€‚
- **ç©ºçµæœæ™‚ã® dtype**ï¼šå…¥åŠ› `num` ã® dtype ã‚’å°Šé‡ã—ã¦ç©º Series ã‚’ç”Ÿæˆ
  â†’ æ¡ç‚¹å´ã® strict ãªå‹ãƒã‚§ãƒƒã‚¯ã«è€ãˆã‚‹ã€‚

---

## å‚è€ƒï¼šæœ€å°ãƒ†ã‚¹ãƒˆ

```python
# 1) ã‚µãƒ³ãƒ—ãƒ«
logs = pd.DataFrame({"id":[1,2,3,4,5,6,7], "num":[1,1,1,2,1,2,2]})
print(consecutive_numbers(logs))
#   ConsecutiveNums
# 0               1

# 2) NaN ãŒæ··ã–ã‚‹ï¼ˆNaNã¯ç„¡è¦–ï¼‰
logs = pd.DataFrame({"id":[1,2,3,4,5], "num":[None, 5,5,5, None]})
print(consecutive_numbers(logs))
#   ConsecutiveNums
# 0               5

# 3) é•·ã„é€£ç¶šã¨è¤‡æ•°å€™è£œ
logs = pd.DataFrame({"id":[1,2,3,4,5,6,7,8,9],
                     "num":[2,2,2,  3,3,3,3,  2,2]})
print(consecutive_numbers(logs))
#   ConsecutiveNums
# 0               2
# 1               3

# 4) ç©º
logs = pd.DataFrame(columns=["id","num"])
print(consecutive_numbers(logs))
# Empty DataFrame with column 'ConsecutiveNums'
```

---

## ã‚‚ã—ã¾ã é€šã‚‰ãªã„å ´åˆã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- æ¡ç‚¹å´ãŒ **å³å¯†ãªä¸¦ã³**ã‚’è¦æ±‚ã—ã¦ã„ã‚‹ â†’ æ—¢ã«æ˜‡é †ã«ã—ãŸãŒã€å¿…è¦ã«å¿œã˜ã¦ã€Œæ•°å€¤ã¨ã—ã¦ã®æ˜‡é †ã€ã«å¤‰ãˆã‚‹
  ï¼ˆ`pd.to_numeric(winners, errors="ignore")` ã‚’ã‚­ãƒ¼ã«ã—ã¦ã‚‚ OKï¼‰
- æ¡ç‚¹å´ãŒ **dtype å›ºå®š**ã‚’è¦æ±‚ã—ã¦ã„ã‚‹ â†’ æœŸå¾…ãŒ `int64` ãªã‚‰ `winners = winners.astype("int64", copy=False)` ã§ãã‚ãˆã‚‹
- `id` ãŒæ—¢ã«æ˜‡é †ã§ã€ä¸è¦ãªã‚½ãƒ¼ãƒˆãŒå«Œã‚ã‚Œã‚‹ â†’ `sort_values` ã‚’æ¡ä»¶ä»˜ãã«ï¼ˆãŸã ã—ä¸€èˆ¬ã«ã¯æ®‹ã—ã¦ OKï¼‰

---

ãªã‚‹ã»ã©ã€‚ã¾ãšã¯ã€Œ**ãªãœè½ã¡ã‚‹ã‹ã‚’è‡ªåˆ†ã§ç‰¹å®šã§ãã‚‹**ã€ã‚ˆã†ã«ã€å¤±æ•—ã—ã‚„ã™ã„è¦å›  â†’ è¨ºæ–­ãƒã‚§ãƒƒã‚¯ â†’ ä¿®æ­£ç‰ˆã‚³ãƒ¼ãƒ‰ â†’ æœ€å°ãƒ†ã‚¹ãƒˆ â†’ è‡ªå‹•ãƒ‡ãƒãƒƒã‚°ï¼ˆå¯è¦–åŒ–ãƒ»ãƒ•ã‚¡ã‚ºãƒ†ã‚¹ãƒˆï¼‰ã®é †ã§ç½®ã„ã¦ãŠãã¾ã™ã€‚
23 ä¸­ 6 ãƒ‘ã‚¹ï¼**åŸºæœ¬ã¯å‹•ããŒç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§å´©ã‚Œã‚‹**ã‚µã‚¤ãƒ³ã§ã™ã€‚

---

## ã‚ˆãè½ã¡ã‚‹åŸå› ãƒˆãƒƒãƒ— 5

1. **`num` å‹ã®ä¸ä¸€è‡´ï¼ˆint ã¨ str ã®æ··åœ¨ï¼‰**
    - SQL ã§ã¯ `num` ã¯ `varchar`ã€‚pandas å´ã§ `1`ï¼ˆintï¼‰ã¨ `"1"`ï¼ˆstrï¼‰ãŒæ··åœ¨ã™ã‚‹ã¨ã€**åŒå€¤åˆ¤å®šãŒã‚ºãƒ¬ã¦é€£ç¶šã‚’è¦‹è½ã¨ã™**/ä½™è¨ˆã«æ‹¾ã†ã€‚

2. **å‰å¾Œã‚¹ãƒšãƒ¼ã‚¹ç­‰ã®æ±šã‚Œï¼ˆ" 1 " vs "1"ï¼‰**
    - SQL ã® `varchar` ç”±æ¥ã ã¨ç¨€ã«æ··å…¥ã€‚**strip ä¸è¶³**ã§ä¸ä¸€è‡´ã€‚

3. **NaN/None ã®æ‰±ã„**
    - `NaN != NaN` ã®ãŸã‚ã€**èª¤ã£ãŸåˆ†å‰²**ã‚„**'nan' æ–‡å­—**ã¨ã—ã¦æ®‹ã—ã¦ã—ã¾ã†ã€‚

4. **ä¸¦ã³é †ã®å–ã‚Šé•ãˆ**
    - é€£ç¶šã®å®šç¾©ã¯ `id` æ˜‡é †ã€‚**æœªã‚½ãƒ¼ãƒˆ**/åˆ¥ã‚­ãƒ¼ã§ã‚½ãƒ¼ãƒˆã™ã‚‹ã¨å…¨éƒ¨ã‚ºãƒ¬ã¾ã™ã€‚

5. **å‡ºåŠ›ã®â€œæ±ºå®šæ€§â€**
    - æ¡ç‚¹å´ãŒå†…éƒ¨ã§å³æ ¼æ¯”è¼ƒã—ã¦ã„ã‚‹ã¨ã€**dtypeï¼ˆæ–‡å­—åˆ—ã§è¿”ã™ã¹ãï¼‰ã‚„ä¸¦ã³**ãŒåŸå› ã§ NG ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚

---

## ãƒ‡ãƒãƒƒã‚°æ‰‹é †ï¼ˆæœ€çŸ­ãƒ«ãƒ¼ãƒˆï¼‰

### 1) ã¾ãšã¯â€œå…¥åŠ›ã®å®Ÿæ…‹â€ã‚’è¦³æ¸¬

```python
print(logs.dtypes)
print(logs.head(10))
print(logs.tail(10))
print("unique types in num:", {type(x) for x in logs["num"].dropna().unique()})
```

- `num` ã« **int ã¨ str ãŒæ··åœ¨**ã—ã¦ã„ãªã„ã‹ã€å‰å¾Œã‚¹ãƒšãƒ¼ã‚¹ãŒãªã„ã‹ç¢ºèªã€‚

### 2) ä¸¦ã³ã¨ NaN ã®ç¢ºèª

```python
print("is_id_sorted:", logs["id"].is_monotonic_increasing)
print("num_has_nan:", logs["num"].isna().any())
```

### 3) ä¸­é–“ç”Ÿæˆç‰©ã‚’è¦—ãï¼ˆrun_id ã¨ run_lenï¼‰

å¾Œè¿°ã® **ãƒ‡ãƒãƒƒã‚°ç‰ˆ** é–¢æ•°ã‚’ä½¿ã£ã¦ `df_debug` ã‚’å‡ºåŠ›ã—ã€
**ã©ã®åŒºé–“ãŒã©ã‚“ãªé•·ã•ã§æ•°ãˆã‚‰ã‚ŒãŸã‹**ã‚’ç›®è¦–ç¢ºèªã€‚

---

## ä¿®æ­£ç‰ˆï¼ˆâ€œvarchar å‰æâ€ã®å³å¯†ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° + RLEï¼‰

> é€£ç¶šã®åˆ¤å®šåˆ—ã¯ **æ–‡å­—åˆ—åŒ–ï¼‹ strip** æ¸ˆã¿ã® `key` ã«çµ±ä¸€ã€‚
> NaN ã¯å®Œå…¨é™¤å¤–ã€‚å‡ºåŠ›ã¯ **æ–‡å­—åˆ—ï¼ˆobject dtypeï¼‰** ã§è¿”ã—ã¾ã™ã€‚

```python
import pandas as pd

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers (as strings) that appear at least three times consecutively by id order.
    Assumes SQL source where `num` is varchar.
    """
    # ã‚¬ãƒ¼ãƒ‰
    if logs is None or logs.empty or not {"id", "num"} <= set(logs.columns):
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="object")})

    # 1) id æ˜‡é †ã«å®‰å®šã‚½ãƒ¼ãƒˆ
    df = logs.loc[:, ["id", "num"]].sort_values("id", kind="mergesort").copy()

    # 2) NaN é™¤å¤–ï¼ˆvarchar ãªã®ã§ None/NaN ã¯â€œå€¤â€ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
    df = df[df["num"].notna()].copy()
    if df.empty:
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="object")})

    # 3) varchar æ­£è¦åŒ–ï¼ˆå‹æ··åœ¨ãƒ»ç©ºç™½å·®ç•°ã‚’å¸åï¼‰
    #    - å…ˆã«æ–‡å­—åˆ—åŒ–â†’strip
    df["key"] = df["num"].astype(str).str.strip()

    # 4) RLE: å¤‰åŒ–ç‚¹â†’ç´¯ç©å’Œã§ run_id
    df["run_id"] = (df["key"].ne(df["key"].shift(1))).cumsum()

    # 5) åŒºé–“é•·é›†è¨ˆ
    run = (
        df.groupby(["key", "run_id"], sort=False)
          .size()
          .reset_index(name="run_len")
    )
    winners = run.loc[run["run_len"] >= 3, "key"].drop_duplicates()

    # 6) æ¡ç‚¹å®‰å®šã®ãŸã‚ã€æ–‡å­—åˆ—ã¨ã—ã¦æ˜‡é †ï¼ˆvarchar æŒ¯ã‚‹èˆã„ï¼‰
    winners = winners.sort_values(kind="mergesort")

    # 7) è¿”å´ï¼ˆvarchar æƒ³å®šãªã®ã§æ–‡å­—åˆ— dtypeï¼‰
    return pd.DataFrame({"ConsecutiveNums": winners.astype("object")})
```

> ã“ã‚Œã§ã€Œ1 ã¨ '1' ã®æ··åœ¨ã€ã€Œ' 1 'ã€ã€ŒNaNã€ã€Œé †åºã€ã€Œdtypeã€ã®åœ°é›·ã‚’ã™ã¹ã¦è¸ã¾ãªã„æ§‹æˆã«ãªã‚Šã¾ã™ã€‚

---

## ä¸­é–“ã‚’è¦—ã‘ã‚‹ãƒ‡ãƒãƒƒã‚°ç‰ˆï¼ˆä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ï¼‰

```python
def consecutive_numbers_debug(logs: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    df = logs.loc[:, ["id", "num"]].sort_values("id", kind="mergesort").copy()
    df["key_raw"] = df["num"]                     # ã¾ãšã¯ç”Ÿã®å‹ã‚’è¦³ã‚‹
    df = df[df["num"].notna()].copy()
    df["key"] = df["num"].astype(str).str.strip() # æ­£è¦åŒ–ã‚­ãƒ¼
    df["run_id"] = (df["key"].ne(df["key"].shift(1))).cumsum()

    run = (
        df.groupby(["key", "run_id"], sort=False)
          .size()
          .reset_index(name="run_len")
    )
    winners = run.loc[run["run_len"] >= 3, "key"].drop_duplicates().sort_values()
    return df, run, winners.to_frame(name="ConsecutiveNums")
```

å‘¼ã³å‡ºã—:

```python
df_debug, runs_debug, out_debug = consecutive_numbers_debug(logs)
print(df_debug.head(20))   # ä¸¦ã³ãƒ»keyãƒ»run_id ã‚’ãƒã‚§ãƒƒã‚¯
print(runs_debug.sort_values(["key","run_id"]))  # å„åŒºé–“ã® run_len
print(out_debug)           # æœ€çµ‚å€™è£œ
```

---

## æœ€å°ãƒ†ã‚¹ãƒˆï¼ˆè½ã¡ã‚„ã™ã„ã‚±ãƒ¼ã‚¹é›†ï¼‰

```python
import pandas as pd

# 1) int ã¨ str æ··åœ¨
logs = pd.DataFrame({"id":[1,2,3,4,5], "num":[1,"1","1","1",2]})
print(consecutive_numbers(logs))
# â†’ "1" ãŒè¿”ã‚‹ã¹ã

# 2) å‰å¾Œã‚¹ãƒšãƒ¼ã‚¹
logs = pd.DataFrame({"id":[1,2,3], "num":[" 2","2 ","2"]})
print(consecutive_numbers(logs))
# â†’ "2"

# 3) NaN ã‚’æŒŸã‚€ï¼ˆç„¡è¦–ï¼‰
logs = pd.DataFrame({"id":[1,2,3,4,5], "num":[None,"3","3","3",None]})
print(consecutive_numbers(logs))
# â†’ "3"

# 4) ä¸è¦å‰‡é †ï¼ˆidã§ä¸¦ã¹æ›¿ãˆã§ãã‚‹ã‹ï¼‰
logs = pd.DataFrame({"id":[3,1,2,4], "num":["7","7","7","8"]})
print(consecutive_numbers(logs))
# â†’ "7"

# 5) é•·ã„é€£ç¶šï¼‹è¤‡æ•°å€™è£œ
logs = pd.DataFrame({"id":[1,2,3,4,5,6,7,8,9],
                     "num":["2","2","2","3","3","3","3","2","2"]})
print(consecutive_numbers(logs))
# â†’ "2","3"ï¼ˆé †ä¸åŒå¯ï¼‰
```

---

## ã•ã‚‰ã«è©°ã‚ã‚‹ãªã‚‰ï¼šè‡ªå‹•ãƒ•ã‚¡ã‚ºãƒ†ã‚¹ãƒˆã§ãƒ­ã‚¸ãƒƒã‚¯æ¤œè¨¼

**rolling æ³•ï¼ˆåŸºæº–å®Ÿè£…ï¼‰**ã¨**RLE æ³•ï¼ˆæœ¬å®Ÿè£…ï¼‰**ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ã§çªãåˆã‚ã›ã¾ã™ã€‚
ä¸¡è€…ãŒå¸¸ã«ä¸€è‡´ã™ã‚‹ãªã‚‰ãƒ­ã‚¸ãƒƒã‚¯ã¯å …ã„ã€ã‚ºãƒ¬ã‚‹ãªã‚‰å…¥åŠ›ç‰¹æ€§ã‚’èª¿ã¹ã¦å¯¾å‡¦ã€‚

```python
import numpy as np
import pandas as pd

def ref_rolling(logs: pd.DataFrame) -> set:
    df = logs.sort_values("id")
    df = df[df["num"].notna()].copy()
    key = df["num"].astype(str).str.strip()
    m = (key.eq(key.shift(1))) & (key.eq(key.shift(2)))
    return set(key[m].unique())

def impl_rle(logs: pd.DataFrame) -> set:
    return set(consecutive_numbers(logs)["ConsecutiveNums"].tolist())

rng = np.random.default_rng(0)
for _ in range(500):
    n = rng.integers(0, 50)
    ids = np.arange(1, n+1)
    rng.shuffle(ids)  # ç„¡ç§©åºãª id ã§ãƒ†ã‚¹ãƒˆ
    # å€¤ã¯ int or str ã‚’æ··åœ¨ã•ã›ã‚‹ã€‚ãŸã¾ã« None ã‚‚å…¥ã‚Œã‚‹
    vals = []
    for i in range(n):
        if rng.random() < 0.1:
            vals.append(None)
        else:
            v = int(rng.integers(0, 5))
            vals.append(str(v) if rng.random() < 0.5 else v)
    logs = pd.DataFrame({"id": ids, "num": vals})
    a = impl_rle(logs)
    b = ref_rolling(logs)
    if a != b:
        print("Mismatch!", logs.head(20), a, b)
        break
```

---

## ã¾ã¨ã‚ï¼ˆãƒ‡ãƒãƒƒã‚°ã®å‹˜æ‰€ï¼‰

- **ã¾ãšå‹ã¨æ±šã‚Œã‚’è¦³ã‚‹**ï¼š`type` é›†åˆãƒ»å…ˆé ­/æœ«å°¾ç¢ºèªã€‚
- **varchar ã‚’å‰æã«â€œæ–‡å­—åˆ—æ­£è¦åŒ–ã‚­ãƒ¼â€ã§åˆ¤å®š**ï¼š`astype(str).str.strip()`ã€‚
- **NaN ã¯å®Œå…¨é™¤å¤–**ï¼ˆå€¤ã§ã¯ãªã„ï¼‰ã€‚
- **`id` æ˜‡é †ã«å®‰å®šã‚½ãƒ¼ãƒˆ**ã—ã¦ã‹ã‚‰åˆ¤å®šã€‚
- **å‡ºåŠ›ã¯ objectï¼ˆæ–‡å­—åˆ—ï¼‰ã§è¿”ã™**ï¼šSQL ã® `varchar` ã¨æƒãˆã‚‹ã€‚

åŸå› ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€**æå‡ºã‚³ãƒ¼ãƒ‰ã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã« `print(logs.dtypes)` ãªã©ã€Œ`logs` ã¨ã„ã†å¤‰æ•°ã€ã‚’ç›´æ¥å‚ç…§ã™ã‚‹ãƒ‡ãƒãƒƒã‚°æ–‡ãŒæ®‹ã£ã¦ã„ã‚‹**ãŸã‚ã§ã™ã€‚
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¸ãƒ£ãƒƒã‚¸ã§ã¯ãã®å¤‰æ•°ã¯å­˜åœ¨ã—ãªã„ã®ã§ `NameError` ã«ãªã‚Šã¾ã™ã€‚
ğŸ‘‰ æå‡ºã¯ **é–¢æ•°ã ã‘** ã«ã—ã¦ãã ã•ã„ï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã« `print(...)` ã‚„ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ç½®ã‹ãªã„ï¼‰ã€‚

---

## æå‡ºç”¨ï¼ˆé–¢æ•°ã®ã¿ãƒ»ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ãªã—ï¼‰

```python
import pandas as pd

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers that appear at least three times consecutively by id order.
    Output schema: single column 'ConsecutiveNums'.
    """
    # ã‚¬ãƒ¼ãƒ‰
    if logs is None or logs.empty or not {"id", "num"} <= set(logs.columns):
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="object")})

    # idæ˜‡é †ã§å®‰å®šã‚½ãƒ¼ãƒˆï¼ˆé€£ç¶šã®åŸºæº–ï¼‰
    df = logs.loc[:, ["id", "num"]].sort_values("id", kind="mergesort").copy()

    # é€£ç¶šåˆ¤å®šã¯æ­£è¦åŒ–ã‚­ãƒ¼ï¼ˆæ–‡å­—åˆ—ï¼‹stripï¼‰ã§è¡Œã†ãŒã€è¿”å´å€¤ã¯å…ƒã®numã‚’ä½¿ã†
    key = df["num"].astype(str).str.strip()
    df["run_id"] = (key != key.shift(1)).cumsum()

    # å„é€£ç¶šåŒºé–“ã®é•·ã•
    run = (
        df.groupby("run_id", sort=False)
          .agg(num=("num", "first"), run_len=("run_id", "size"))
          .reset_index(drop=True)
    )

    winners = run.loc[run["run_len"] >= 3, "num"].drop_duplicates()

    # ä¸¦ã³ã¯å®‰å®šåŒ–ï¼ˆæ•°å€¤ãªã‚‰æ•°å€¤é †ã€ãã†ã§ãªã‘ã‚Œã°æ–‡å­—åˆ—é †ï¼‰
    if pd.api.types.is_numeric_dtype(df["num"]):
        winners = winners.sort_values(kind="mergesort")
    else:
        winners = winners.astype(str).sort_values(kind="mergesort")

    return pd.DataFrame({"ConsecutiveNums": winners.reset_index(drop=True)})
```

> é‡è¦ï¼š**ã“ã‚Œä»¥å¤–ã®ã‚³ãƒ¼ãƒ‰ã¯æå‡ºã—ãªã„**ã§ãã ã•ã„ã€‚`print(...)`ã€ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œã€`if __name__ == "__main__":` ãªã©ã‚‚å¤–ã—ã¦ãã ã•ã„ï¼ˆç’°å¢ƒã«ã‚ˆã£ã¦ã¯å¤±æ•—è¦å› ã«ãªã‚Šã¾ã™ï¼‰ã€‚

---

## ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ‡ãƒãƒƒã‚°ã—ãŸã„ã¨ãã®ã‚³ãƒ„ï¼ˆæå‡ºã«ã¯å«ã‚ãªã„ï¼‰

- ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã¯**åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«**ã‹ `if __name__ == "__main__":` ã®ä¸­ã«ç½®ãã€‚
- è‡ªåˆ†ã§ `logs = pd.DataFrame({...})` ã‚’ç”¨æ„ã—ã¦ã‹ã‚‰ `print(consecutive_numbers(logs))` ã‚’å‘¼ã¶ã€‚
- å‹ãƒ»æ±šã‚Œã‚’ç¢ºèªã™ã‚‹ã¨ãã¯ï¼š

    ```python
    print(logs.dtypes)
    print({type(x) for x in logs["num"].dropna().unique()})
    ```

ã“ã‚Œã§ `NameError` ã¯è§£æ¶ˆã—ã€æ¡ç‚¹ç’°å¢ƒã§ã‚‚å‹•ãã¯ãšã§ã™ã€‚

åŸå› ã¯ã‚ºãƒãƒªã€**æœ€çµ‚å‡ºåŠ›ãŒæ–‡å­—åˆ—ï¼ˆ"1"ï¼‰ã«ãªã£ã¦ã„ãŸ**ã“ã¨ã§ã™ã€‚
å‰å›ã®å®Ÿè£…ã§ã¯é€£ç¶šåˆ¤å®šã®ãŸã‚ã« `num` ã‚’ã„ã£ãŸã‚“ **æ–‡å­—åˆ—æ­£è¦åŒ–**ï¼ˆ`astype(str).str.strip()`ï¼‰ã—ã¦ã„ã¾ã—ãŸãŒã€ãã® **æ­£è¦åŒ–ã‚­ãƒ¼ã‚’ãã®ã¾ã¾è¿”ã—ã¦ã„ãŸ**ãŸã‚ã€
è©•ä¾¡å´ãŒæœŸå¾…ã™ã‚‹ **æ•´æ•° 1** ã§ã¯ãªã **æ–‡å­—åˆ— "1"** ã«ãªã£ã¦ã„ã¾ã—ãŸã€‚

ä¸‹ã®ä¿®æ­£ç‰ˆã¯ã€**é€£ç¶šåˆ¤å®šã¯æ–‡å­—åˆ—ã‚­ãƒ¼ã§å³å¯†ã«**è¡Œã„ã€**è¿”å´æ™‚ã¯ â€œã™ã¹ã¦ãŒæ•´æ•°è¡¨ç¾ãªã‚‰ int64 ã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦è¿”ã™â€** ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ï¼ˆæ•´æ•°ã§ãªã„å€¤ãŒæ··ã˜ã‚‹ã‚±ãƒ¼ã‚¹ã§ã¯æ–‡å­—åˆ—ã®ã¾ã¾è¿”ã—ã¾ã™ï¼‰ã€‚

---

```python
import pandas as pd
import re

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers that appear at least three times consecutively by id order.
    Output schema: single column 'ConsecutiveNums'.

    - åˆ¤å®šã¯æ–‡å­—åˆ—æ­£è¦åŒ–ã‚­ãƒ¼ã§è¡Œã„ï¼ˆæ··åœ¨/ç©ºç™½å¯¾ç­–ï¼‰
    - è¿”å´ã¯ã€å€™è£œãŒã™ã¹ã¦æ•´æ•°è¡¨ç¾ãªã‚‰ int64 ã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦è¿”ã™
      ï¼ˆè©•ä¾¡ç³»ãŒ 1 ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ãŸã‚ï¼‰
    """
    # ã‚¬ãƒ¼ãƒ‰
    if logs is None or logs.empty or not {"id", "num"} <= set(logs.columns):
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    # 1) é€£ç¶šã®åŸºæº–ã¯ id æ˜‡é †
    df = logs.loc[:, ["id", "num"]].sort_values("id", kind="mergesort").copy()

    # 2) NaN ã¯å¯¾è±¡å¤–ï¼ˆå€¤ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
    df = df[df["num"].notna()].copy()
    if df.empty:
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    # 3) æ–‡å­—åˆ—æ­£è¦åŒ–ã‚­ãƒ¼ï¼ˆæ··åœ¨å‹/å‰å¾Œç©ºç™½ã‚’å¸åï¼‰
    key = df["num"].astype(str).str.strip()
    df["run_id"] = (key != key.shift(1)).cumsum()

    # 4) é€£ç¶šåŒºé–“ã®é•·ã•ã‚’é›†è¨ˆï¼ˆrun_id å˜ä½ï¼‰
    runs = (
        df.assign(key=key)
          .groupby("run_id", sort=False)
          .agg(key=("key", "first"), run_len=("run_id", "size"))
          .reset_index(drop=True)
    )

    winners_key = runs.loc[runs["run_len"] >= 3, "key"].drop_duplicates()

    if winners_key.empty:
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    # 5) è¿”å´å‹ã®æ±ºå®šï¼š
    #    å€™è£œãŒã™ã¹ã¦ã€Œæ•´æ•°ã ã‘ã§æ§‹æˆã€ã•ã‚Œã¦ã„ã‚Œã° int64 ã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦è¿”ã™ã€‚
    #    ãã‚Œä»¥å¤–ï¼ˆå°æ•°ã‚„è‹±å­—ãŒæ··ã˜ã‚‹ç­‰ï¼‰ã¯æ–‡å­—åˆ—ã®ã¾ã¾è¿”ã™ã€‚
    int_pat = re.compile(r"^[+-]?\d+$")
    all_int_like = winners_key.map(lambda s: bool(int_pat.match(s))).all()

    if all_int_like:
        out = winners_key.astype("int64").sort_values(kind="mergesort").reset_index(drop=True)
        return pd.DataFrame({"ConsecutiveNums": out})
    else:
        # æ•°å­—ä»¥å¤–ãŒæ··ã–ã‚‹å ´åˆã¯æ–‡å­—åˆ—ã§è¿”ã™ï¼ˆä¸¦ã³ã¯å®‰å®šåŒ–ï¼‰
        out = winners_key.sort_values(kind="mergesort").reset_index(drop=True).astype("object")
        return pd.DataFrame({"ConsecutiveNums": out})
```

### ã“ã‚Œã§ç›´ã‚‹ç†ç”±

- é€£ç¶šåˆ¤å®šã¯ã€Œè¡¨è¨˜ã‚†ã‚Œã€ã«å¼·ã„ **æ–‡å­—åˆ—ã‚­ãƒ¼**ã§å®Ÿæ–½ï¼ˆ`"1"`, `1`, `" 1 "` ã§ã‚‚åŒä¸€æ‰±ã„ï¼‰ã€‚
- ã—ã‹ã— **è¿”å´æ™‚ã¯è©•ä¾¡ç³»ã®æœŸå¾…**ã«åˆã‚ã›ã€**ã™ã¹ã¦æ•´æ•°è¡¨ç¾ãªã‚‰ int64 ã«å¤‰æ›**ã—ã¦è¿”ã™ãŸã‚ã€
  `1`ï¼ˆæ•°å€¤ï¼‰ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã€`"1"` ã¨ã®ä¸ä¸€è‡´ãŒè§£æ¶ˆã•ã‚Œã¾ã™ã€‚

### ã‚µãƒ³ãƒ—ãƒ«ï¼ˆè³ªå•ã®ã‚±ãƒ¼ã‚¹ï¼‰

```python
logs = pd.DataFrame({"id":[1,2,3,4,5,6], "num":[1,1,1,2,1,2]})
print(consecutive_numbers(logs))
#   ConsecutiveNums
# 0               1   <- æ•°å€¤ (int64)
```

> æå‡ºã®éš›ã¯ã€ã“ã®é–¢æ•°ä»¥å¤–ï¼ˆprint ã‚„ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼‰ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

é€Ÿåº¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ `groupby`/`size`/`drop_duplicates`/æ–‡å­—åˆ—å‡¦ç†ã‚ãŸã‚Šã§ã™ã€‚
ä¸‹ã¯ **ã»ã¼ NumPy ã ã‘**ã§ãƒ©ãƒ³é•·ï¼ˆRLEï¼‰ã‚’å‡ºã—ã¦é‡ã„ `groupby` ã‚’ç„¡ãã—ãŸé«˜é€Ÿç‰ˆã€‚
åˆ¤å®šã‚­ãƒ¼ã¯å‹ã‚’è¦‹ã¦ **æ•°å€¤ã«çµ±ä¸€ã§ãã‚‹ãªã‚‰çµ±ä¸€**ï¼ˆ"1" ã¨ 1 ã‚’åŒä¸€è¦–ï¼‰ã€æœ€å¾Œã®å‡ºåŠ›ã¯ **å¯èƒ½ãªã‚‰ int64** ã«è½ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```python
import pandas as pd
import numpy as np

def consecutive_numbers(logs: pd.DataFrame) -> pd.DataFrame:
    """
    Return numbers that appear at least three times consecutively by id order.
    - åˆ¤å®šã¯ã§ãã‚‹ã ã‘æ•°å€¤ã«çµ±ä¸€ï¼ˆ"1" ã¨ 1 ã‚’åŒä¸€è¦–ï¼‰
    - RLE ã‚’ NumPy ã§å®Ÿè£…ã—ã¦ groupby ã‚’å›é¿
    - è¿”å´ã¯å¯èƒ½ãªã‚‰ int64ï¼ˆæ¡ç‚¹ã®æœŸå¾…ã«åˆã‚ã›ã‚‹ï¼‰
    """
    # å…¥åŠ›ã‚¬ãƒ¼ãƒ‰
    if logs is None or logs.empty or not {"id", "num"} <= set(logs.columns):
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    # id æ˜‡é †ã€‚æ—¢ã«å˜èª¿å¢—åŠ ãªã‚‰ã‚½ãƒ¼ãƒˆçœç•¥ï¼ˆé«˜é€ŸåŒ–ï¼‰
    df = logs.loc[:, ["id", "num"]]
    if not df["id"].is_monotonic_increasing:
        df = df.sort_values("id", kind="mergesort", ignore_index=True)
    else:
        df = df.reset_index(drop=True)

    # NaN ã¯é€£ç¶šåˆ¤å®šã®å¯¾è±¡å¤–ï¼ˆä¸¸ã”ã¨é™¤å¤–ï¼‰
    mask_valid = df["num"].notna().to_numpy()
    if not mask_valid.any():
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})
    s = df.loc[mask_valid, "num"]

    # å¯èƒ½ãªã‚‰æ•°å€¤ã«çµ±ä¸€ï¼ˆ"1" ã¨ 1 ã‚’åŒä¸€è¦–ã€å‡ºåŠ›ã‚‚æ•°å€¤åŒ–ã—ã‚„ã™ããªã‚‹ï¼‰
    if pd.api.types.is_numeric_dtype(s):
        key = s.to_numpy()                  # æ•°å€¤ã®ã¾ã¾
        out_vals = key                      # å‡ºåŠ›å€™è£œã‚‚æ•°å€¤
        out_is_numeric = True
    else:
        coerced = pd.to_numeric(s, errors="coerce")
        if coerced.notna().all():
            key = coerced.to_numpy()        # ã™ã¹ã¦æ•°å€¤åŒ–ã§ããŸ
            out_vals = key
            out_is_numeric = True
        else:
            # æ•°å€¤åŒ–ã§ããªã„å€¤ãŒæ··ã˜ã‚‹å ´åˆã¯æ–‡å­—åˆ—ã§åˆ¤å®šï¼ˆstrip ã¯é«˜ã‚³ã‚¹ãƒˆãªã®ã§çœç•¥ï¼‰
            key = s.astype(str).to_numpy()
            out_vals = key
            out_is_numeric = False

    n = key.shape[0]
    if n == 0:
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    # --- RLEï¼ˆNumPyï¼‰---
    # å¤‰åŒ–ç‚¹ï¼ˆå…ˆé ­ã¯å¿…ãšå¤‰åŒ–ç‚¹ï¼‰
    change = np.empty(n, dtype=bool)
    change[0] = True
    change[1:] = key[1:] != key[:-1]

    # é€£ç¶šãƒ–ãƒ­ãƒƒã‚¯IDï¼ˆ0..k-1ï¼‰
    run_id = np.cumsum(change) - 1

    # å„ãƒ–ãƒ­ãƒƒã‚¯é•·ã¨é–‹å§‹ä½ç½®
    run_len = np.bincount(run_id)                 # shape: (k,)
    start_idx = np.flatnonzero(change)            # shape: (k,)

    # é•·ã•>=3 ã®ãƒ–ãƒ­ãƒƒã‚¯ã®å…ˆé ­å€¤ã‚’å€™è£œã«
    ok = run_len >= 3
    if not ok.any():
        return pd.DataFrame({"ConsecutiveNums": pd.Series([], dtype="int64")})

    winners = out_vals[start_idx[ok]]

    # é‡è¤‡é™¤å»ï¼ˆé †åºä¿æŒãƒ»é«˜é€Ÿï¼‰
    winners = pd.unique(winners)

    # å‡ºåŠ› dtype ã‚’ç¢ºå®šï¼ˆå¯èƒ½ãªã‚‰ int64ï¼‰
    if out_is_numeric:
        # æµ®å‹•å°æ•°ãŒç´›ã‚Œã¦ã‚‚å…¨ã¦æ•´æ•°å€¤ãªã‚‰ int64 ã«è½ã¨ã™
        arr = np.asarray(winners)
        if np.issubdtype(arr.dtype, np.floating):
            if np.all(np.isfinite(arr)) and np.all(arr == np.floor(arr)):
                winners = arr.astype("int64", copy=False)
        elif np.issubdtype(arr.dtype, np.integer):
            winners = arr
        else:
            # ãã‚Œä»¥å¤–ã®æ•°å€¤å‹ã¯ä¸€æ—¦æ•´æ•°åŒ–ã‚’è©¦ã¿ã‚‹
            try:
                winners = arr.astype("int64", copy=False)
            except Exception:
                pass
        return pd.DataFrame({"ConsecutiveNums": pd.Series(winners)})
    else:
        # æ–‡å­—åˆ—ã§ã‚‚ã€å…¨ã¦æ•´æ•°è¡¨ç¾ãªã‚‰ int64 ã«å¤‰æ›ï¼ˆæ¡ç‚¹äº’æ›ï¼‰
        coerced_w = pd.to_numeric(pd.Series(winners), errors="coerce")
        if coerced_w.notna().all() and np.all(coerced_w == np.floor(coerced_w)):
            return pd.DataFrame({"ConsecutiveNums": coerced_w.astype("int64")})
        # ãã†ã§ãªã‘ã‚Œã°æ–‡å­—åˆ—ã®ã¾ã¾è¿”ã™
        return pd.DataFrame({"ConsecutiveNums": pd.Series(winners, dtype="object")})
```

## é€Ÿããªã‚‹ç†ç”±ï¼ˆè¦ç‚¹ï¼‰

- **NumPy ã§ RLE**ï¼š`groupby(["num","run_id"]).size()` ã‚’ã‚„ã‚ã€`change â†’ run_id â†’ bincount` ã§ O(n)ãƒ»ä½ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰åŒ–ã€‚
- **ã‚½ãƒ¼ãƒˆå›é¿**ï¼š`id` ãŒå˜èª¿å¢—åŠ ãªã‚‰ã‚½ãƒ¼ãƒˆã›ãšã«é€²ã‚€ã€‚
- **ä¸è¦ãªæ­£è¦åŒ–ã‚’å›é¿**ï¼šæ–‡å­—åˆ—ã® `.str.strip()` ã‚„æ­£è¦è¡¨ç¾ã‚’ã‚„ã‚ã€ã¾ãšæ•°å€¤çµ±ä¸€ã‚’è©¦ã¿ã‚‹ã€‚
- **é‡è¤‡é™¤å»ã¯ `pd.unique`**ï¼šé †åºä¿æŒã§é«˜é€Ÿã€`drop_duplicates` ã‚ˆã‚Šè»½ã„ã€‚
- **â€œä»»æ„é †åºâ€ä»•æ§˜åˆ©ç”¨**ï¼šå‡ºåŠ›ã®ä¸¦ã³æ›¿ãˆã‚’çœç•¥ï¼ˆè©•ä¾¡ã«ä¸è¦ï¼‰ã€‚

### è¨ˆç®—é‡

- å‰å‡¦ç†ï¼ˆå¿…è¦ãªã‚‰ã‚½ãƒ¼ãƒˆï¼‰: `O(n log n)`ï¼ˆå˜èª¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰
- RLEï¼ˆNumPyï¼‰: `O(n)` æ™‚é–“ãƒ» `O(n)` ç©ºé–“ï¼ˆè¿½åŠ åˆ—ãªã—ï¼‰

> ã“ã‚Œã§ `groupby` ç‰ˆã‚ˆã‚Š **CPUãƒ»ãƒ¡ãƒ¢ãƒªã®ä¸¡æ–¹**ãŒã‹ãªã‚Šè»½ããªã‚‹ã¯ãšã§ã™ã€‚
> ã•ã‚‰ã«è©°ã‚ã‚‹ãªã‚‰ã€å…¥åŠ›ãŒå¸¸ã«æ•°å€¤ã ã¨åˆ†ã‹ã£ã¦ã„ã‚‹ç’°å¢ƒã§ã¯ã€Œæ•°å€¤çµ±ä¸€ã®åˆ†å²ã€ã‚’å‰Šã£ã¦ã‚‚ã£ã¨è»½ãã§ãã¾ã™ã€‚
